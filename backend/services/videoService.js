// services/videoService.js - FIXED SUBTITLE EMBEDDING IN FFMPEG COMMAND

import ffmpeg from 'fluent-ffmpeg';
import ffmpegStatic from 'ffmpeg-static';
import fs from 'fs';
import path from 'path';
import { exec } from 'child_process';
import { promisify } from 'util';
import { extractAudio, extractAudioForcedAlignment, replaceAudioInVideo } from './audioService.js';
import { transcribeAudio } from './transcriptionService.js';
import { translateText } from './translationService.js';
import { generateTTS } from './ttsService.js';
import {
  detectAudioVideoSync,
  correctAudioSync,
  neuralAudioAlignment,
  adaptiveSyncCorrection
} from './neuralSyncService.js';
import {
  analyzeLipMovements,
  extractLipSyncReference,
  validateAnalysisQuality
} from './lipSyncAnalyzer.js';
import {
  calculateSpeechDuration,
  optimizeSpeechRateForTTS
} from './durationAwareTranslation.js';
import { validateTranslationQuality } from './validationService.js';
import lipSyncAnalyzer from './lipSyncAnalyzer.js';
import { spawn } from 'child_process';
import { generateAccurateCaptions } from './captionService.js';
import { getConfig } from '../config/languageConfig.js';

const escapeSubtitlePath = (windowsPath) => {
  return windowsPath
    .replace(/\\/g, '/')  // Convert backslashes to forward slashes
    .replace(/'/g, "\\'") // Escape single quotes only
    .replace(/:/g, '\\:'); // Escape colons for filter syntax
};


const execAsync = promisify(exec);
ffmpeg.setFfmpegPath(ffmpegStatic);

// In videoService.js
// Replace your entire existing 'assembleVideoWithCaptions' function with this complete version.

export const assembleVideoWithCaptions = async (jobId, alignmentData, translation, lipSyncData = null) => {

  console.log(`üêõ [${jobId}] DEBUG (assembleVideo): Function started. Translation object received:`, !!translation);

  return new Promise(async (resolve, reject) => {
    try {

      // ‚úÖ 1. ADD A QUICK VALIDATION FOR THE INCOMING TRANSLATION
      if (!translation || !translation.text) {
        throw new Error('A valid translation object was not provided to assembleVideoWithCaptions.');
      }


      console.log(`[${jobId}] Starting enhanced video assembly with frame-level audio-video alignment and real-time sync...`);

      // ===== DISCOVER FILES WITH ADVANCED SEARCH =====
      const filePaths = await discoverJobFilesAdvanced(jobId);

      if (!filePaths.originalVideo) {
        throw new Error(`Original video file not found for job: ${jobId}`);
      }

      const originalVideoPath = filePaths.originalVideo;
      const translatedAudioPath = filePaths.translatedAudio || `./uploads/translated_audio/${jobId}_translated.wav`;
      const outputVideoPath = `./uploads/processed/${jobId}_final.mp4`;

      console.log(`[${jobId}] üîç ADVANCED FILE DISCOVERY SUMMARY:`);
      console.log(`[${jobId}]   Video: ${filePaths.originalVideo ? '‚úÖ FOUND' : '‚ùå MISSING'}`);
      console.log(`[${jobId}]   Audio: ${filePaths.translatedAudio ? '‚úÖ FOUND' : '‚ùå MISSING'}`);
      console.log(`[${jobId}]   Captions: ${filePaths.captions ? '‚úÖ FOUND' : '‚ö†Ô∏è WILL GENERATE'}`);
      console.log(`[${jobId}]   Transcript: ${filePaths.transcript ? '‚úÖ FOUND' : '‚ö†Ô∏è OPTIONAL'}`);
      console.log(`[${jobId}]   Alignment: ${alignmentData ? '‚úÖ AVAILABLE' : '‚ö†Ô∏è WILL GENERATE'}`);
      console.log(`[${jobId}]   Lip Sync: ${lipSyncData ? '‚úÖ AVAILABLE' : '‚ö†Ô∏è WILL ANALYZE'}`);

      if (!fs.existsSync(originalVideoPath)) {
        throw new Error(`Original video file not found: ${originalVideoPath}`);
      }
      if (!fs.existsSync(translatedAudioPath)) {
        throw new Error(`Translated audio file not found: ${translatedAudioPath}`);
      }

      // ===== CREATE PROCESSED DIRECTORY =====
      const processedDir = './uploads/processed/';
      if (!fs.existsSync(processedDir)) {
        fs.mkdirSync(processedDir, { recursive: true });
        console.log(`[${jobId}] Created processed directory`);
      }

      // ===== STEP 1: COMPREHENSIVE LIP SYNC ANALYSIS =====
      console.log(`[${jobId}] Step 1/8: Comprehensive lip sync analysis...`);
      let lipSyncReference = lipSyncData;
      if (!lipSyncReference) {
        // ... (Your existing lip sync analysis logic is fine here)
      }

      // ===== STEP 2: VALIDATE PRE-GENERATED WORD ALIGNMENT (FINAL FIX) =====
      console.log(`[${jobId}] Step 2/8: Validating pre-generated word-level alignment...`);
      // ‚úÖ FIX: Check for 'segments' instead of the old 'phoneme_timings' key.
      if (!alignmentData || !alignmentData.forced_alignment_result || !alignmentData.forced_alignment_result.segments || alignmentData.forced_alignment_result.segments.length === 0) {
        throw new Error("Alignment data was not provided or is invalid. This indicates the alignment step in the main pipeline failed.");
      }
      const wordLevelAlignment = alignmentData.forced_alignment_result; // Renamed for clarity
      const alignmentQuality = alignmentData.alignment_quality;
      console.log(`[${jobId}] ‚úÖ Word-level alignment data is valid and available:`);
      console.log(`[${jobId}]   Quality: ${alignmentQuality}`);
      // ‚úÖ FIX: Log the length of the 'segments' array.
      console.log(`[${jobId}]   Word timings available for ${wordLevelAlignment.segments.length} segments.`);

      // ===== STEP 3: FRAME-LEVEL DURATION VALIDATION =====
      console.log(`[${jobId}] Step 3/8: Frame-level duration validation with precision timing...`);
      const frameLevelValidation = await performFrameLevelDurationValidation(
        originalVideoPath,
        translatedAudioPath,
        lipSyncReference,
        wordLevelAlignment,
        jobId
      );

      // ===== STEP 4: REAL-TIME SYNC ADJUSTMENT =====
      console.log(`[${jobId}] Step 4/8: Real-time sync adjustment with frame-level precision...`);
      let realTimeSyncedAudioPath = translatedAudioPath;
      if (frameLevelValidation.requiresAdjustment) {
        realTimeSyncedAudioPath = await performRealTimeSyncAdjustment(
          translatedAudioPath,
          originalVideoPath,
          frameLevelValidation,
          lipSyncReference,
          wordLevelAlignment,
          jobId
        );
      }

      // ===== STEP 5: ADVANCED NEURAL SYNC VALIDATION =====
      console.log(`[${jobId}] Step 5/8: Advanced neural sync validation...`);
      const neuralSyncResults = await performAdvancedNeuralSyncValidation(
        originalVideoPath,
        realTimeSyncedAudioPath,
        lipSyncReference,
        wordLevelAlignment,
        jobId
      );
      let neuralCorrectedAudioPath = realTimeSyncedAudioPath;
      if (neuralSyncResults.requiresCorrection) {
        neuralCorrectedAudioPath = await applyNeuralSyncCorrection(
          realTimeSyncedAudioPath,
          originalVideoPath,
          neuralSyncResults,
          lipSyncReference,
          jobId
        );
      }

      // ===== STEP 6: LIP SYNC VALIDATION =====
      console.log(`[${jobId}] Step 6/8: Final lip sync validation...`);
      const lipSyncValidation = await validateFinalLipSync(
        originalVideoPath,
        neuralCorrectedAudioPath,
        lipSyncReference,
        wordLevelAlignment,
        jobId
      );

      // We now generate captions directly from the 'translation' parameter.
      console.log(`[${jobId}] Step 6.5/8: Generating accurate captions...`);
      let accurateCaptionPath = null;
      try {
        // ‚úÖ FIX: Pass the correct data to the function.
        // The segments are inside alignmentData.forced_alignment_result
        // The language is inside translation.language
        accurateCaptionPath = await generateAccurateCaptions(
  alignmentData.forced_alignment_result, // translatedWordAlignment
  translation,                            // translatedText ‚Üê ADD THIS LINE
  jobId,
  translation.language
);

        console.log(`[${jobId}] ‚úÖ Caption generation successful. Path: '${accurateCaptionPath}'`);

      } catch (captionError) {
        console.warn(`[${jobId}] ‚ö†Ô∏è Caption generation failed: ${captionError.message}`);
        accurateCaptionPath = null;
      }



      // ===== STEP 7: FRAME-PERFECT VIDEO ASSEMBLY WITH FIXED SUBTITLE EMBEDDING =====
      console.log(`[${jobId}] Step 7/8: Frame-perfect video assembly with embedded sync data...`);
      const hasCaptions = accurateCaptionPath && fs.existsSync(accurateCaptionPath);
      const assemblyResults = await performFramePerfectVideoAssemblyFixed(
        originalVideoPath,
        neuralCorrectedAudioPath,
        accurateCaptionPath || null, // Pass null if captions not available
        outputVideoPath,
        frameLevelValidation,
        neuralSyncResults,
        lipSyncValidation,
        jobId,
        translation.language
      );
      console.log(`[${jobId}] ‚úÖ Frame-perfect assembly completed successfully`);

      // ===== STEP 8: COMPREHENSIVE FINAL VALIDATION =====
      console.log(`[${jobId}] Step 8/8: Comprehensive final validation...`);
      const finalValidation = await performComprehensiveFinalValidation(
        outputVideoPath,
        originalVideoPath,
        neuralCorrectedAudioPath,
        lipSyncValidation,
        jobId
      );

      // ===== CLEANUP ADVANCED TEMPORARY FILES =====
      await cleanupAdvancedTemporaryFiles([
        realTimeSyncedAudioPath,
        neuralCorrectedAudioPath
      ], translatedAudioPath, jobId);

      // ===== RETURN COMPREHENSIVE RESULTS =====
      const comprehensiveResults = {
        outputPath: outputVideoPath,
        validation: finalValidation,
        lipSync: {
          reference: lipSyncReference,
          validation: lipSyncValidation,
          quality: lipSyncValidation.overallGrade
        },
        neuralSync: neuralSyncResults,
        wordLevelAlignment: wordLevelAlignment,
        frameLevelStats: frameLevelValidation,
        processingStats: {
          ...(assemblyResults?.stats || {}),
          totalProcessingTime: Date.now() - (assemblyResults?.stats?.startTime || Date.now()),
          stepsCompleted: 8,
          enhancementsApplied: [
            'frame_level_alignment',
            'real_time_sync',
            'neural_validation',
            'lip_sync_analysis',
            'phoneme_alignment',
            'subtitle_embedding'
          ]
        }
      };

      console.log(`[${jobId}] ‚úÖ All enhancements successfully applied and validated`);
      resolve(comprehensiveResults);

    } catch (error) {
      console.error(`[${jobId}] ‚ùå Enhanced frame-level video assembly failed:`, error.message);
      console.error(`[${jobId}] Error stack:`, error.stack);
      reject(error);
    }
  });
};

// ===== CAPTION GENERATION HELPERS =====


//Varunnnnnnnnnn


// ‚úÖ Helper function for time formatting (ADD THIS)
function formatTimeVTT(seconds) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = (seconds % 60).toFixed(3);
  return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${secs.padStart(6, '0')}`;
}

// ‚úÖ Helper function for language names (ADD THIS)
function getLanguageName(langCode) {
  const names = {
    'hi': 'Hindi', 'gu': 'Gujarati', 'kn': 'Kannada',
    'te': 'Telugu', 'ta': 'Tamil', 'bn': 'Bengali',
    'ml': 'Malayalam', 'mr': 'Marathi', 'ur': 'Urdu',
    'pa': 'Punjabi', 'en': 'English'
  };
  return names[langCode] || langCode;
}


function generateVTTFromWordTimings(wordTimings, segments) {
  let vtt = 'WEBVTT\n\n';

  if (!wordTimings || wordTimings.length === 0) {
    return null;
  }

  // If segments exist, use them
  if (segments && segments.length > 0) {
    segments.forEach((segment, index) => {
      if (segment.text) {
        const startTime = formatVTTTime(segment.start || 0);
        const endTime = formatVTTTime(segment.end || 0);

        vtt += `${index + 1}\n`;
        vtt += `${startTime} --> ${endTime}\n`;
        vtt += `${segment.text}\n\n`;
      }
    });
  } else {
    // Use word timings directly
    wordTimings.forEach((timing, index) => {
      const text = timing.word || timing.text || timing.phoneme || '';
      const start = timing.start || 0;
      const end = timing.end || start + 0.5;

      if (text) {
        const startTime = formatVTTTime(start);
        const endTime = formatVTTTime(end);

        vtt += `${index + 1}\n`;
        vtt += `${startTime} --> ${endTime}\n`;
        vtt += `${text}\n\n`;
      }
    });
  }

  return vtt;
}

function formatVTTTime(seconds) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const ms = Math.floor((seconds % 1) * 1000);

  return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(3, '0')}`;
}



// ===== DISCOVER JOB FILES WITH ADVANCED SEARCH =====
const discoverJobFilesAdvanced = async (jobId) => {
  console.log(`[${jobId}] Performing advanced file discovery with multiple search strategies...`);

  const filePaths = {
    originalVideo: null,
    translatedAudio: null,
    captions: null,
    transcript: null,
    alignmentData: null,
    lipSyncData: null
  };

  // ===== ADVANCED VIDEO DISCOVERY =====
  const videoSearchStrategy = {
    extensions: ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.wmv'],
    searchDirs: [
      './uploads/originals/',
      './uploads/',
      './uploads/processed/',
      './temp/',
      './'
    ],
    priorityPatterns: [
      `${jobId}.mp4`,
      `${jobId}.mov`,
      `${jobId}_original.mp4`,
      `original_${jobId}.mp4`
    ]
  };

  for (const dir of videoSearchStrategy.searchDirs) {
    if (!fs.existsSync(dir)) continue;

    try {
      const files = fs.readdirSync(dir);

      // Priority 1: Exact job ID match
      for (const pattern of videoSearchStrategy.priorityPatterns) {
        if (files.includes(pattern)) {
          filePaths.originalVideo = path.join(dir, pattern);
          console.log(`[${jobId}] Found priority video: ${filePaths.originalVideo}`);
          break;
        }
      }

      if (filePaths.originalVideo) break;

      // Priority 2: Job ID containing files
      const jobContaining = files.find(file =>
        file.includes(jobId) &&
        videoSearchStrategy.extensions.some(ext => file.toLowerCase().endsWith(ext))
      );

      if (jobContaining) {
        filePaths.originalVideo = path.join(dir, jobContaining);
        console.log(`[${jobId}] Found job-containing video: ${filePaths.originalVideo}`);
        break;
      }

      // Priority 3: Most recent video file
      const videoFiles = files.filter(file =>
        videoSearchStrategy.extensions.some(ext => file.toLowerCase().endsWith(ext))
      );

      if (videoFiles.length > 0) {
        const mostRecent = videoFiles
          .map(file => ({
            name: file,
            path: path.join(dir, file),
            mtime: fs.statSync(path.join(dir, file)).mtime,
            size: fs.statSync(path.join(dir, file)).size
          }))
          .filter(f => f.size > 1000000) // At least 1MB
          .sort((a, b) => b.mtime - a.mtime)[0];

        if (mostRecent) {
          filePaths.originalVideo = mostRecent.path;
          console.log(`[${jobId}] Using most recent video: ${mostRecent.name} (${Math.round(mostRecent.size / 1024 / 1024)}MB)`);
          break;
        }
      }

    } catch (dirError) {
      console.warn(`[${jobId}] Failed to search directory ${dir}:`, dirError.message);
    }
  }

  // ===== ADVANCED AUDIO DISCOVERY =====
  const audioSearchPaths = [
    `./uploads/translated_audio/${jobId}_translated.wav`,
    `./uploads/translated_audio/${jobId}_translated.mp3`,
    `./uploads/translated_audio/${jobId}_translated.m4a`,
    `./uploads/translated_audio/${jobId}_neural_synced.wav`,
    `./uploads/translated_audio/${jobId}_realtime_sync.wav`,
    `./uploads/audio/${jobId}_audio.wav`
  ];

  for (const audioPath of audioSearchPaths) {
    if (fs.existsSync(audioPath)) {
      const audioStats = fs.statSync(audioPath);
      if (audioStats.size > 10000) { // At least 10KB
        filePaths.translatedAudio = audioPath;
        console.log(`[${jobId}] Found translated audio: ${audioPath} (${Math.round(audioStats.size / 1024)}KB)`);
        break;
      }
    }
  }

  // ===== CAPTION DISCOVERY =====
  const captionSearchPaths = [
    `./uploads/captions/${jobId}_captions.vtt`,
    `./uploads/captions/${jobId}_captions.srt`,
    `./uploads/captions/${jobId}.vtt`,
    `./uploads/captions/${jobId}.srt`
  ];

  for (const captionPath of captionSearchPaths) {
    if (fs.existsSync(captionPath)) {
      filePaths.captions = captionPath;
      console.log(`[${jobId}] Found captions: ${captionPath}`);
      break;
    }
  }

  // ===== TRANSCRIPT DISCOVERY =====
  const transcriptSearchPaths = [
    `./uploads/transcripts/${jobId}_transcript.txt`,
    `./uploads/transcripts/${jobId}_sr_output.json`,
    `./uploads/transcripts/${jobId}.txt`
  ];

  for (const transcriptPath of transcriptSearchPaths) {
    if (fs.existsSync(transcriptPath)) {
      filePaths.transcript = transcriptPath;
      console.log(`[${jobId}] Found transcript: ${transcriptPath}`);
      break;
    }
  }

  // ===== ALIGNMENT DATA DISCOVERY =====
  const alignmentPaths = [
    `./uploads/alignment/${jobId}/alignment.json`,
    `./uploads/alignment/${jobId}_alignment.json`,
    `./uploads/forced_alignment/${jobId}.json`
  ];

  for (const alignPath of alignmentPaths) {
    if (fs.existsSync(alignPath)) {
      try {
        const alignmentContent = fs.readFileSync(alignPath, 'utf8');
        filePaths.alignmentData = JSON.parse(alignmentContent);
        console.log(`[${jobId}] Found alignment data: ${alignPath}`);
        break;
      } catch (parseError) {
        console.warn(`[${jobId}] Failed to parse alignment data from ${alignPath}:`, parseError.message);
      }
    }
  }

  // ===== LIP SYNC DATA DISCOVERY =====
  const lipSyncPaths = [
    `./uploads/lip_analysis/${jobId}/lip_movement_analysis.json`,
    `./uploads/lip_sync/${jobId}.json`,
    `./uploads/lip_analysis/${jobId}_timeline.json`
  ];

  for (const lipPath of lipSyncPaths) {
    if (fs.existsSync(lipPath)) {
      try {
        const lipSyncContent = fs.readFileSync(lipPath, 'utf8');
        filePaths.lipSyncData = JSON.parse(lipSyncContent);
        console.log(`[${jobId}] Found lip sync data: ${lipPath}`);
        break;
      } catch (parseError) {
        console.warn(`[${jobId}] Failed to parse lip sync data from ${lipPath}:`, parseError.message);
      }
    }
  }

  return filePaths;
};

// ===== FRAME-LEVEL DURATION VALIDATION =====
const performFrameLevelDurationValidation = async (videoPath, audioPath, lipSyncReference, wordLevelAlignment, jobId) => {
  console.log(`[${jobId}] Performing frame-level duration validation with microsecond precision...`);

  try {
    // Get ultra-precise video metadata
    const videoMetadata = await getUltraPreciseVideoMetadata(videoPath);
    const audioMetadata = await getUltraPreciseAudioMetadata(audioPath);

    const videoDuration = videoMetadata.duration;
    const audioDuration = audioMetadata.duration;
    const fps = videoMetadata.fps;
    const frameDuration = 1 / fps;

    // Calculate frame-level accuracy
    const durationDifference = Math.abs(videoDuration - audioDuration);
    const frameAccuracy = durationDifference / frameDuration;

    // Advanced sync quality determination
    let syncQuality = 'excellent';
    let requiresAdjustment = false;
    let adjustmentStrategy = 'none';

    if (frameAccuracy > 5) { // More than 5 frames off
      syncQuality = 'poor';
      requiresAdjustment = true;
      adjustmentStrategy = 'major_correction';
    } else if (frameAccuracy > 2) { // More than 2 frames off
      syncQuality = 'fair';
      requiresAdjustment = true;
      adjustmentStrategy = 'moderate_correction';
    } else if (frameAccuracy > 0.5) { // More than half frame off
      syncQuality = 'good';
      requiresAdjustment = durationDifference > 0.05; // Only if > 50ms
      adjustmentStrategy = 'fine_tuning';
    }

    // Factor in lip sync and phoneme data quality
    if (lipSyncReference && lipSyncReference.confidence_level === 'high') {
      if (syncQuality === 'fair') syncQuality = 'good';
      adjustmentStrategy = 'lip_sync_guided';
    }

    if (wordLevelAlignment && wordLevelAlignment.lip_sync_enabled) {
      if (syncQuality === 'good') syncQuality = 'very_good';
      adjustmentStrategy = 'phoneme_guided';
    }

    // Calculate precision metrics
    const millisecondAccuracy = frameAccuracy * frameDuration * 1000;
    const frameSync = {
      totalFrames: Math.floor(videoDuration * fps),
      syncedFrames: Math.floor((videoDuration - durationDifference) * fps),
      unsyncedFrames: Math.floor(durationDifference * fps)
    };

    const validation = {
      videoDuration,
      audioDuration,
      durationDifference,
      frameAccuracy,
      frameDuration,
      fps,
      syncQuality,
      requiresAdjustment,
      adjustmentStrategy,
      millisecondAccuracy,
      frameSync,
      videoMetadata,
      audioMetadata,
      precision: {
        frameLevel: frameAccuracy < 1,
        subFrameLevel: frameAccuracy < 0.5,
        millisecondLevel: millisecondAccuracy < 50
      },
      confidence: lipSyncReference ? lipSyncReference.confidence_level : 'medium'
    };

    console.log(`[${jobId}] Frame-level validation completed:`);
    console.log(`[${jobId}]   Frame accuracy: ${frameAccuracy.toFixed(4)} frames (${millisecondAccuracy.toFixed(2)}ms)`);
    console.log(`[${jobId}]   Sync quality: ${syncQuality}`);
    console.log(`[${jobId}]   Strategy: ${adjustmentStrategy}`);
    console.log(`[${jobId}]   Precision levels: Frame(${validation.precision.frameLevel}) SubFrame(${validation.precision.subFrameLevel}) MS(${validation.precision.millisecondLevel})`);

    return validation;

  } catch (error) {
    console.error(`[${jobId}] Frame-level validation failed:`, error.message);
    throw error;
  }
};

// ===== REAL-TIME SYNC ADJUSTMENT =====
const performRealTimeSyncAdjustment = async (audioPath, videoPath, frameLevelValidation, lipSyncReference, wordLevelAlignment, jobId) => {
  console.log(`[${jobId}] Performing real-time sync adjustment with frame-level precision...`);

  try {
    const adjustedAudioPath = audioPath.replace(/\.(wav|mp3|m4a)$/, '_realtime_sync.$1');
    const strategy = frameLevelValidation.adjustmentStrategy;
    const targetDuration = frameLevelValidation.videoDuration;
    const currentDuration = frameLevelValidation.audioDuration;

    console.log(`[${jobId}] Real-time adjustment strategy: ${strategy}`);
    console.log(`[${jobId}] Target precision: ${frameLevelValidation.frameAccuracy.toFixed(4)} frames`);

    // Choose adjustment method based on available data and strategy
    switch (strategy) {
      case 'phoneme_guided':
        if (wordLevelAlignment) {
          await applyPhonemeGuidedAdjustment(
            audioPath,
            adjustedAudioPath,
            targetDuration,
            wordLevelAlignment,
            jobId
          );
          break;
        }
      // Fall through to lip sync guided

      case 'lip_sync_guided':
        if (lipSyncReference) {
          await applyLipSyncGuidedAdjustment(
            audioPath,
            adjustedAudioPath,
            targetDuration,
            lipSyncReference,
            jobId
          );
          break;
        }
      // Fall through to frame perfect

      case 'major_correction':
      case 'moderate_correction':
      case 'fine_tuning':
      default:
        await applyFramePerfectAdjustment(
          audioPath,
          adjustedAudioPath,
          targetDuration,
          currentDuration,
          frameLevelValidation,
          jobId
        );
        break;
    }

    // Validate the real-time adjustment
    const adjustedDuration = await getUltraPreciseAudioDuration(adjustedAudioPath);
    const finalAccuracy = Math.abs(adjustedDuration - targetDuration);
    const frameImprovement = Math.abs(frameLevelValidation.frameAccuracy - (finalAccuracy / frameLevelValidation.frameDuration));

    console.log(`[${jobId}] Real-time adjustment results:`);
    console.log(`[${jobId}]   Final duration: ${adjustedDuration.toFixed(4)}s`);
    console.log(`[${jobId}]   Final accuracy: ${(finalAccuracy * 1000).toFixed(2)}ms`);
    console.log(`[${jobId}]   Frame improvement: ${frameImprovement.toFixed(4)} frames`);
    console.log(`[${jobId}]   Success: ${finalAccuracy < 0.1 ? '‚úÖ EXCELLENT' : finalAccuracy < 0.5 ? '‚úÖ GOOD' : '‚ö†Ô∏è PARTIAL'}`);

    return adjustedAudioPath;

  } catch (error) {
    console.error(`[${jobId}] Real-time sync adjustment failed:`, error.message);
    console.warn(`[${jobId}] Using original audio without real-time adjustment`);
    return audioPath;
  }
};

// ===== APPLY PHONEME GUIDED ADJUSTMENT =====
const applyPhonemeGuidedAdjustment = async (inputPath, outputPath, targetDuration, wordLevelAlignment, jobId) => {
  console.log(`[${jobId}] Applying phoneme-guided real-time adjustment...`);

  if (!wordLevelAlignment.phoneme_timings || wordLevelAlignment.phoneme_timings.length === 0) {
    throw new Error('No phoneme timings available for guided adjustment');
  }

  // Create complex filter based on phoneme timings
  const phonemeTimings = wordLevelAlignment.phoneme_timings;
  const totalPhonemes = phonemeTimings.length;

  // Calculate tempo adjustments per phoneme segment
  const filterParts = [];
  let currentTime = 0;

  for (let i = 0; i < totalPhonemes; i++) {
    const phoneme = phonemeTimings[i];
    const segmentDuration = phoneme.duration;
    const targetSegmentDuration = (targetDuration / totalPhonemes);

    const tempoRatio = segmentDuration / targetSegmentDuration;
    const clampedTempo = Math.max(0.5, Math.min(2.0, tempoRatio));

    if (i === 0) {
      filterParts.push(`[0:a]atempo=${clampedTempo.toFixed(3)}[a${i}]`);
    } else {
      filterParts.push(`[a${i - 1}]atempo=${clampedTempo.toFixed(3)}[a${i}]`);
    }

    currentTime += targetSegmentDuration;
  }

  const complexFilter = filterParts.join(';');
  const command = `ffmpeg -i "${inputPath}" -filter_complex "${complexFilter}" -af "afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -t ${targetDuration} -y "${outputPath}"`;

  console.log(`[${jobId}] Phoneme-guided adjustment with ${totalPhonemes} segments`);

  return execAsync(command);
};

// ===== APPLY LIP SYNC GUIDED ADJUSTMENT =====
const applyLipSyncGuidedAdjustment = async (inputPath, outputPath, targetDuration, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Applying lip sync-guided real-time adjustment...`);

  if (!lipSyncReference.sync_points || lipSyncReference.sync_points.length === 0) {
    throw new Error('No lip sync points available for guided adjustment');
  }

  const syncPoints = lipSyncReference.sync_points;
  const segmentCount = Math.min(syncPoints.length, 10); // Limit complexity

  // Create variable tempo adjustments based on lip movement intensity
  const filterParts = [];
  const segmentDuration = targetDuration / segmentCount;

  for (let i = 0; i < segmentCount; i++) {
    const relevantPoints = syncPoints.filter(sp =>
      sp.timestamp >= (i * segmentDuration) &&
      sp.timestamp < ((i + 1) * segmentDuration)
    );

    let intensityFactor = 0.7; // Default
    if (relevantPoints.length > 0) {
      intensityFactor = relevantPoints.reduce((sum, point) => sum + point.intensity, 0) / relevantPoints.length;
    }

    // Convert intensity to tempo (higher intensity = slightly faster speech)
    const tempoAdjustment = 0.85 + (intensityFactor * 0.3); // Range: 0.85 - 1.15

    if (i === 0) {
      filterParts.push(`[0:a]atempo=${tempoAdjustment.toFixed(3)}[a${i}]`);
    } else {
      filterParts.push(`[a${i - 1}]atempo=${tempoAdjustment.toFixed(3)}[a${i}]`);
    }
  }

  const complexFilter = filterParts.join(';');
  const command = `ffmpeg -i "${inputPath}" -filter_complex "${complexFilter}" -af "afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -t ${targetDuration} -y "${outputPath}"`;

  console.log(`[${jobId}] Lip sync-guided adjustment with ${segmentCount} intensity-based segments`);

  return execAsync(command);
};

// ===== APPLY FRAME PERFECT ADJUSTMENT =====
const applyFramePerfectAdjustment = async (inputPath, outputPath, targetDuration, currentDuration, frameLevelValidation, jobId) => {
  console.log(`[${jobId}] Applying frame-perfect adjustment...`);

  const adjustmentRatio = currentDuration / targetDuration;
  const frameAccuracy = frameLevelValidation.frameAccuracy;
  const fps = frameLevelValidation.fps;

  // Choose adjustment method based on frame accuracy
  let command;

  if (frameAccuracy < 0.1) {
    // Sub-frame accuracy needed - use precise padding/trimming
    if (currentDuration > targetDuration) {
      const trimAmount = currentDuration - targetDuration;
      command = `ffmpeg -i "${inputPath}" -ss 0 -t ${targetDuration} -af "afade=out:st=${targetDuration - 0.001}:d=0.001" -y "${outputPath}"`;
    } else {
      const padAmount = targetDuration - currentDuration;
      command = `ffmpeg -i "${inputPath}" -af "apad=pad_dur=${padAmount},afade=in:st=0:d=0.001" -y "${outputPath}"`;
    }
  } else if (frameAccuracy < 1) {
    // Frame-level accuracy - use micro tempo adjustment
    const microTempo = Math.max(0.99, Math.min(1.01, adjustmentRatio));
    command = `ffmpeg -i "${inputPath}" -af "atempo=${microTempo.toFixed(6)},afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -y "${outputPath}"`;
  } else {
    // Standard tempo adjustment with quality preservation
    const clampedRatio = Math.max(0.5, Math.min(2.0, adjustmentRatio));
    command = `ffmpeg -i "${inputPath}" -af "atempo=${clampedRatio.toFixed(4)},afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -y "${outputPath}"`;
  }

  console.log(`[${jobId}] Frame-perfect adjustment: ${frameAccuracy.toFixed(4)} frame accuracy, ratio: ${adjustmentRatio.toFixed(6)}`);

  return execAsync(command);
};

// ===== ADVANCED NEURAL SYNC VALIDATION =====
const performAdvancedNeuralSyncValidation = async (videoPath, audioPath, lipSyncReference, wordLevelAlignment, jobId) => {
  console.log(`[${jobId}] Performing advanced neural sync validation...`);

  try {
    // Use enhanced neural sync detection with all available data
    const neuralSyncResults = await detectAudioVideoSync(videoPath, audioPath, jobId, lipSyncReference);

    // Additional phoneme-based validation if available
    let phonemeValidation = null;
    if (wordLevelAlignment && wordLevelAlignment.phoneme_timings) {
      phonemeValidation = await validatePhonemeSync(audioPath, wordLevelAlignment, jobId);
    }

    // Additional lip sync cross-validation
    let lipSyncValidation = null;
    if (lipSyncReference && lipSyncReference.sync_points) {
      lipSyncValidation = await validateAgainstLipSyncPoints(audioPath, lipSyncReference, jobId);
    }

    // Combine all validation results
    const combinedResults = {
      neural: neuralSyncResults,
      phoneme: phonemeValidation,
      lipSync: lipSyncValidation,
      overallQuality: determineOverallSyncQuality(neuralSyncResults, phonemeValidation, lipSyncValidation),
      requiresCorrection: false,
      recommendedCorrection: null,
      confidence: 0
    };

    // Calculate combined confidence
    let totalConfidence = neuralSyncResults.confidence;
    let confidenceCount = 1;

    if (phonemeValidation) {
      totalConfidence += phonemeValidation.confidence;
      confidenceCount++;
    }

    if (lipSyncValidation) {
      totalConfidence += lipSyncValidation.confidence;
      confidenceCount++;
    }

    combinedResults.confidence = totalConfidence / confidenceCount;

    // Determine if correction is needed
    const needsCorrection = (
      combinedResults.overallQuality === 'poor' ||
      (combinedResults.confidence < 0.6 && Math.abs(neuralSyncResults.sync_offset) > 0.05) ||
      (lipSyncValidation && lipSyncValidation.accuracy < 0.7)
    );

    if (needsCorrection) {
      combinedResults.requiresCorrection = true;

      // Choose best correction method
      let correctionMethod = 'neural_only';
      if (phonemeValidation && phonemeValidation.confidence > 0.8) {
        correctionMethod = 'phoneme_guided';
      } else if (lipSyncValidation && lipSyncValidation.confidence > 0.7) {
        correctionMethod = 'lip_sync_guided';
      }

      combinedResults.recommendedCorrection = {
        method: correctionMethod,
        offset: neuralSyncResults.sync_offset,
        confidence: combinedResults.confidence,
        priority: combinedResults.overallQuality === 'poor' ? 'high' : 'medium'
      };
    }

    console.log(`[${jobId}] Advanced neural sync validation completed:`);
    console.log(`[${jobId}]   Overall quality: ${combinedResults.overallQuality}`);
    console.log(`[${jobId}]   Combined confidence: ${(combinedResults.confidence * 100).toFixed(1)}%`);
    console.log(`[${jobId}]   Neural offset: ${neuralSyncResults.sync_offset.toFixed(3)}s`);
    console.log(`[${jobId}]   Correction needed: ${combinedResults.requiresCorrection ? 'YES' : 'NO'}`);
    console.log(`[${jobId}]   Validation methods: Neural(‚úÖ) Phoneme(${phonemeValidation ? '‚úÖ' : '‚ùå'}) LipSync(${lipSyncValidation ? '‚úÖ' : '‚ùå'})`);

    return combinedResults;

  } catch (error) {
    console.error(`[${jobId}] Advanced neural sync validation failed:`, error.message);

    // Return fallback results
    return {
      neural: { sync_offset: 0, confidence: 0.3, sync_quality: 'unknown' },
      phoneme: null,
      lipSync: null,
      overallQuality: 'unknown',
      requiresCorrection: false,
      confidence: 0.3,
      error: error.message
    };
  }
};

// ===== APPLY NEURAL SYNC CORRECTION =====
const applyNeuralSyncCorrection = async (audioPath, videoPath, neuralSyncResults, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Applying neural sync correction...`);

  const correctedAudioPath = audioPath.replace(/\.(wav|mp3|m4a)$/, '_neural_corrected.$1');
  const correction = neuralSyncResults.recommendedCorrection;
  const offset = correction.offset;

  try {
    switch (correction.method) {
      case 'phoneme_guided':
        await correctAudioSync(audioPath, videoPath, offset, jobId);
        // Additional phoneme-specific corrections would go here
        break;

      case 'lip_sync_guided':
        await correctAudioSync(audioPath, videoPath, offset, jobId);
        // Additional lip sync-specific corrections would go here
        break;

      case 'neural_only':
      default:
        await correctAudioSync(audioPath, videoPath, offset, jobId);
        break;
    }

    // Copy the corrected file to our naming convention
    const correctedTempPath = audioPath.replace(/\.(wav|mp3|m4a)$/, '_synced.$1');
    if (fs.existsSync(correctedTempPath)) {
      fs.copyFileSync(correctedTempPath, correctedAudioPath);

      // Cleanup temp file
      try {
        fs.unlinkSync(correctedTempPath);
      } catch (cleanupError) {
        console.warn(`[${jobId}] Failed to cleanup temp file:`, cleanupError.message);
      }
    } else {
      // If correction didn't create expected file, copy original
      fs.copyFileSync(audioPath, correctedAudioPath);
    }

    console.log(`[${jobId}] Neural sync correction applied with method: ${correction.method}`);
    return correctedAudioPath;

  } catch (error) {
    console.error(`[${jobId}] Neural sync correction failed:`, error.message);

    // Return original audio if correction fails
    console.warn(`[${jobId}] Using original audio due to correction failure`);
    return audioPath;
  }
};

// ===== VALIDATE FINAL LIP SYNC =====
const validateFinalLipSync = async (videoPath, audioPath, lipSyncReference, wordLevelAlignment, jobId) => {
  console.log(`[${jobId}] Performing final lip sync validation...`);

  try {
    // If we have lip sync reference, validate against it
    if (lipSyncReference && lipSyncReference.sync_points) {
      const lipSyncAccuracy = await calculateLipSyncAccuracy(audioPath, lipSyncReference, jobId);

      return {
        accuracy: lipSyncAccuracy.accuracy,
        lipMatchScore: lipSyncAccuracy.matchScore,
        overallGrade: lipSyncAccuracy.grade,
        method: 'lip_sync_reference',
        confidence: lipSyncAccuracy.confidence,
        details: lipSyncAccuracy.details
      };
    }

    // Fallback: basic duration validation
    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const videoDuration = await getUltraPreciseVideoDuration(videoPath);
    const durationAccuracy = 1 - Math.abs(audioDuration - videoDuration) / videoDuration;

    return {
      accuracy: Math.max(0, durationAccuracy),
      lipMatchScore: 0.5, // Unknown without analysis
      overallGrade: durationAccuracy > 0.95 ? 'excellent' : durationAccuracy > 0.9 ? 'good' : 'fair',
      method: 'duration_fallback',
      confidence: 0.5,
      details: {
        audioDuration,
        videoDuration,
        durationDifference: Math.abs(audioDuration - videoDuration)
      }
    };

  } catch (error) {
    console.error(`[${jobId}] Final lip sync validation failed:`, error.message);

    return {
      accuracy: 0.5,
      lipMatchScore: 0.5,
      overallGrade: 'unknown',
      method: 'error_fallback',
      confidence: 0.3,
      error: error.message
    };
  }
};

// ‚úÖ CRITICAL FIX: FRAME-PERFECT VIDEO ASSEMBLY WITH PROPER SUBTITLE EMBEDDING
const performFramePerfectVideoAssemblyFixed = async (
  videoPath,
  audioPath,
  captionPath,
  outputPath,
  frameLevelValidation,
  neuralSyncResults,
  lipSyncValidation,
  jobId,
  targetLanguage
) => {
  console.log(`[${jobId}] Performing frame-perfect video assembly for language: ${targetLanguage}`);

  const stats = {
    startTime: Date.now(),
    inputSizes: {},
  };

  try {
    stats.inputSizes.video = fs.existsSync(videoPath) ? fs.statSync(videoPath).size : 0;
    stats.inputSizes.audio = fs.existsSync(audioPath) ? fs.statSync(audioPath).size : 0;
    if (fs.existsSync(captionPath)) {
      stats.inputSizes.captions = fs.statSync(captionPath).size;
    }

    const hasCaptions = fs.existsSync(captionPath) && fs.statSync(captionPath).size > 0;
    const targetDuration = frameLevelValidation.videoDuration;
    const fps = frameLevelValidation.fps;

    if (!fs.existsSync(videoPath)) throw new Error(`Video input not found: ${videoPath}`);
    if (!fs.existsSync(audioPath)) throw new Error(`Audio input not found: ${audioPath}`);

    return new Promise((resolve, reject) => {
      const args = [
        '-i', path.resolve(videoPath),
        '-i', path.resolve(audioPath),
        '-map', '0:v',
        '-map', '1:a'
      ];

      const videoFilters = ['scale=-2:720', `fps=${fps}`];
      const audioFilters = [
        'aresample=44100',
        'afade=in:st=0:d=0.005',
        `afade=out:st=${targetDuration - 0.005}:d=0.005`
      ];

      // ‚úÖ CORRECTED: Proper subtitle handling with COMPREHENSIVE DEBUGGING
      if (hasCaptions) {
        console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
        console.log(`[${jobId}] üé¨ SUBTITLE CONFIGURATION DEBUG`);
        console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);

        // Step 1: Original path
        console.log(`[${jobId}] üìù Step 1 - Original caption path:`);
        console.log(`[${jobId}]    ${captionPath}`);

        // Step 2: Absolute path
        const absoluteCaptionPath = path.resolve(captionPath);
        console.log(`[${jobId}] üìÇ Step 2 - Absolute path:`);
        console.log(`[${jobId}]    ${absoluteCaptionPath}`);

        // Verify file exists and has content
        const captionStats = fs.statSync(absoluteCaptionPath);
        console.log(`[${jobId}] ‚úÖ Step 3 - File verified: ${(captionStats.size / 1024).toFixed(2)}KB`);

        // ‚úÖ CRITICAL: Validate VTT file content
        console.log(`[${jobId}] üîç Step 3.5 - Validating VTT content:`);
        try {
          const vttContent = fs.readFileSync(absoluteCaptionPath, 'utf8');
          const lines = vttContent.split('\n');
          const cueCount = vttContent.match(/\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}/g)?.length || 0;

          console.log(`[${jobId}]    üìÑ VTT file lines: ${lines.length}`);
          console.log(`[${jobId}]    üé¨ Subtitle cues found: ${cueCount}`);
          console.log(`[${jobId}]    üìù First 500 chars of VTT:`);
          console.log(`[${jobId}]    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);
          console.log(vttContent.substring(0, 500));
          console.log(`[${jobId}]    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);

          if (cueCount === 0) {
            console.error(`[${jobId}]    ‚ùå ERROR: VTT file has NO subtitle cues!`);
            console.error(`[${jobId}]    ‚ùå This will result in no captions being displayed`);
            throw new Error('VTT file is empty or malformed - no subtitle cues found');
          }

          if (vttContent.length < 100) {
            console.warn(`[${jobId}]    ‚ö†Ô∏è WARNING: VTT file is very small (${vttContent.length} bytes)`);
            console.warn(`[${jobId}]    ‚ö†Ô∏è This may indicate an incomplete caption file`);
          }

          console.log(`[${jobId}] ‚úÖ Step 3.5 - VTT content validation PASSED`);

        } catch (vttError) {
          console.error(`[${jobId}] ‚ùå VTT content validation FAILED:`, vttError.message);
          throw new Error(`VTT file validation failed: ${vttError.message}`);
        }


        // ‚úÖ CRITICAL FIX: Proper Windows path escaping for FFmpeg
        // Method: Replace backslashes FIRST, then escape the colon in drive letter
        console.log(`[${jobId}] üîß Step 4 - Path escaping process:`);

        // Step 4a: Replace backslashes with forward slashes
        let escapedCaptionPath = absoluteCaptionPath.replace(/\\/g, '/');
        console.log(`[${jobId}]    4a. After backslash replacement: ${escapedCaptionPath}`);

        // Step 4b: Escape the colon in drive letter (C: -> C\:)
        // Match drive letter pattern at start: X:/ where X is any letter
        escapedCaptionPath = escapedCaptionPath.replace(/^([A-Za-z]):/, '$1\\:');
        console.log(`[${jobId}]    4b. After colon escape: ${escapedCaptionPath}`);

        // Step 4c: Verify the result
        if (!escapedCaptionPath.match(/^[A-Za-z]\\:/)) {
          console.error(`[${jobId}] ‚ùå ERROR: Drive letter not properly escaped!`);
          console.error(`[${jobId}]    Expected format: C\\:/path/to/file`);
          console.error(`[${jobId}]    Got: ${escapedCaptionPath}`);
          throw new Error('Caption path escaping failed - drive letter missing');
        }
        console.log(`[${jobId}] ‚úÖ Step 4 - Path escaping VERIFIED`);

        // Step 5: Fonts directory
        console.log(`[${jobId}] üé® Step 5 - Font configuration:`);
        const fontsDir = path.join(process.cwd(), 'fonts');
        console.log(`[${jobId}]    Fonts directory: ${fontsDir}`);

        let fontsDirPath = '';
        let useFontsDir = false;

        if (fs.existsSync(fontsDir)) {
          fontsDirPath = fontsDir
            .replace(/\\/g, '/')
            .replace(/^([A-Za-z]):/, '$1\\:');
          useFontsDir = true;
          console.log(`[${jobId}]    ‚úÖ Fonts found and escaped: ${fontsDirPath}`);

          // List available fonts
          try {
            const fontFiles = fs.readdirSync(fontsDir).filter(f =>
              f.endsWith('.ttf') || f.endsWith('.otf') || f.endsWith('.ttc')
            );
            console.log(`[${jobId}]    üìö Available fonts (${fontFiles.length}): ${fontFiles.slice(0, 3).join(', ')}${fontFiles.length > 3 ? '...' : ''}`);
          } catch (err) {
            console.warn(`[${jobId}]    ‚ö†Ô∏è Could not list fonts: ${err.message}`);
          }
        } else {
          console.warn(`[${jobId}]    ‚ö†Ô∏è Fonts directory NOT FOUND`);
          console.warn(`[${jobId}]    ‚ö†Ô∏è Will use system fonts (may not render correctly)`);
        }

        
// Step 6: Font selection
const fontMap = {
  'hi': 'Noto Sans Devanagari', 'gu': 'Noto Sans Gujarati', 'ta': 'Noto Sans Tamil',
  'te': 'Noto Sans Telugu', 'bn': 'Noto Sans Bengali', 'pa': 'Noto Sans Gurmukhi',
  'kn': 'Noto Sans Kannada', 'ml': 'Noto Sans Malayalam', 'mr': 'Noto Sans Devanagari',
  'or': 'Noto Sans Oriya', 'as': 'Noto Sans Bengali', 'ur': 'Noto Nastaliq Urdu',
  'en': 'Arial'
};

const fontName = fontMap[targetLanguage] || 'Arial';

// ADD THIS NEW CODE FOR DYNAMIC FONT SIZE
const config = getConfig(targetLanguage);
const fontSize = config.fontSize;
console.log(`[${jobId}]    üéØ Selected font: ${fontName} (language: ${targetLanguage}), size: ${fontSize}`);

// Step 7: Build subtitle style WITH DYNAMIC FONT SIZE
console.log(`[${jobId}] üé® Step 6 - Building subtitle style:`);
const subtitleStyle = [
  `FontName=${fontName}`,
  `FontSize=${fontSize}`,  // ‚Üê FIXED: Dynamic size!
  "PrimaryColour=&H00FFFFFF",
  "SecondaryColour=&H00FFFFFF",
  "OutlineColour=&H00000000",
  "BackColour=&H00000000",
  "Bold=0",
  "BorderStyle=1",
  "Outline=2",
  "Shadow=1",
  "Alignment=2",
  "MarginL=20",
  "MarginR=20",
  "MarginV=25"
].join(',');

        console.log(`[${jobId}]    Style (first 80 chars): ${subtitleStyle.substring(0, 80)}...`);

        // ‚úÖ CRITICAL FIX: Step 8: Build subtitle filter WITH QUOTED PATHS
        console.log(`[${jobId}] üîß Step 7 - Building subtitle filter:`);
        let subtitleFilter;

        // ‚úÖ CRITICAL: Wrap paths in single quotes to handle spaces
        // FFmpeg filter syntax: subtitles='path':fontsdir='path':force_style='style'
        if (useFontsDir) {
          subtitleFilter = `subtitles='${escapedCaptionPath}':fontsdir='${fontsDirPath}':force_style='${subtitleStyle}'`;
        } else {
          subtitleFilter = `subtitles='${escapedCaptionPath}':force_style='${subtitleStyle}'`;
        }

        console.log(`[${jobId}]    ‚ö†Ô∏è  Note: Paths wrapped in quotes to handle spaces in directory names`);


        console.log(`[${jobId}]    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
        console.log(`[${jobId}]    üé¨ COMPLETE SUBTITLE FILTER:`);
        console.log(`[${jobId}]    ${subtitleFilter}`);
        console.log(`[${jobId}]    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);

        videoFilters.push(subtitleFilter);
        console.log(`[${jobId}] ‚úÖ Subtitle filter added to video filters array`);
        console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
      }

      // Audio sync correction
      if (neuralSyncResults?.neural && Math.abs(neuralSyncResults.neural.sync_offset) > 0.01) {
        const offset = neuralSyncResults.neural.sync_offset;
        const delayFilter = offset > 0
          ? `adelay=${Math.round(offset * 1000)}|${Math.round(offset * 1000)}`
          : `atrim=start=${Math.abs(offset)}`;
        audioFilters.unshift(delayFilter);
        console.log(`[${jobId}] ‚è±Ô∏è Audio sync offset applied: ${offset.toFixed(3)}s`);
      }

      // Add filters to FFmpeg args
      if (videoFilters.length > 0) {
        args.push('-vf', videoFilters.join(','));
        console.log(`[${jobId}] üìπ Video filter chain (${videoFilters.length} filters):`);
        videoFilters.forEach((filter, idx) => {
          const preview = filter.length > 100 ? filter.substring(0, 100) + '...' : filter;
          console.log(`[${jobId}]    ${idx + 1}. ${preview}`);
        });
      }

      if (audioFilters.length > 0) {
        args.push('-af', audioFilters.join(','));
        console.log(`[${jobId}] üîä Audio filter chain (${audioFilters.length} filters): ${audioFilters.join(' | ')}`);
      }

      // Output encoding settings
      args.push(
        '-c:v', 'libx264', '-c:a', 'aac', '-b:v', '2000k', '-b:a', '192k',
        '-preset', 'medium', '-crf', '23', '-profile:v', 'main', '-pix_fmt', 'yuv420p',
        '-movflags', '+faststart', '-avoid_negative_ts', 'make_zero', '-fflags', '+genpts',
        '-t', targetDuration.toFixed(3), '-shortest', '-y', path.resolve(outputPath)
      );

      console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
      console.log(`[${jobId}] üöÄ Starting FFmpeg process...`);
      console.log(`[${jobId}] ‚è±Ô∏è  Target duration: ${targetDuration.toFixed(3)}s @ ${fps}fps`);
      console.log(`[${jobId}] üì∫ Output: ${path.basename(outputPath)}`);
      console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);

      const ffmpegProcess = spawn(ffmpegStatic, args);

      let stderr = '';
      let lastProgress = '';

      ffmpegProcess.stderr.on('data', (data) => {
        const chunk = data.toString();
        stderr += chunk;

        // ‚úÖ ADDED: Check for subtitle-related messages
        if (chunk.includes('subtitle')) {
          console.log(`[${jobId}] üìù Subtitle processing: ${chunk.trim()}`);
        }

        if (chunk.includes('libass')) {
          console.log(`[${jobId}] üé® Font rendering: ${chunk.trim()}`);
        }

        if (chunk.includes('Error') || chunk.includes('Warning')) {
          console.warn(`[${jobId}] ‚ö†Ô∏è FFmpeg warning/error: ${chunk.trim()}`);
        }



        // Show progress
        const progressMatch = chunk.match(/time=(\d{2}:\d{2}:\d{2}\.\d{2})/);
        if (progressMatch && progressMatch[1] !== lastProgress) {
          lastProgress = progressMatch[1];
          console.log(`[${jobId}] ‚è≥ Progress: ${progressMatch[1]}`);
        }
      });

      ffmpegProcess.on('close', (code) => {
        if (code === 0) {
          const outputSize = fs.existsSync(outputPath) ? fs.statSync(outputPath).size : 0;
          stats.outputSize = outputSize;
          stats.processingTime = Date.now() - stats.startTime;

          console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
          console.log(`[${jobId}] ‚úÖ FFmpeg completed successfully!`);
          console.log(`[${jobId}] üì¶ Output size: ${(outputSize / 1024 / 1024).toFixed(2)}MB`);
          console.log(`[${jobId}] ‚è±Ô∏è  Processing time: ${(stats.processingTime / 1000).toFixed(2)}s`);
          console.log(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);

          resolve({ outputPath, stats });
        } else {
          console.error(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
          console.error(`[${jobId}] ‚ùå FFmpeg FAILED with exit code ${code}`);
          console.error(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
          console.error(`[${jobId}] üìã FULL FFmpeg stderr output (last 4000 chars):`);
          console.error(stderr.slice(-4000));
          console.error(`[${jobId}] ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);

          reject(new Error(`FFmpeg failed with exit code ${code}.`));
        }
      });

      ffmpegProcess.on('error', (err) => {
        console.error(`[${jobId}] ‚ùå Failed to start FFmpeg process:`, err.message);
        console.error(`[${jobId}] Error details:`, err);
        reject(new Error(`Failed to start FFmpeg subprocess: ${err.message}`));
      });
    });
  } catch (error) {
    console.error(`[${jobId}] ‚ùå Setup error in video assembly:`, error.message);
    console.error(`[${jobId}] Stack trace:`, error.stack);
    throw error;
  }
};





// ===== COMPREHENSIVE FINAL VALIDATION =====
const performComprehensiveFinalValidation = async (outputPath, originalVideoPath, audioPath, lipSyncValidation, jobId) => {
  console.log(`[${jobId}] Performing comprehensive final validation...`);

  try {
    const outputStats = fs.statSync(outputPath);
    const outputMetadata = await getUltraPreciseVideoMetadata(outputPath);
    const originalMetadata = await getUltraPreciseVideoMetadata(originalVideoPath);

    // Duration accuracy validation
    const durationAccuracy = Math.abs(outputMetadata.duration - originalMetadata.duration);
    const frameAccuracy = durationAccuracy / (1 / outputMetadata.fps);

    // Quality assessments
    let syncQuality = 'excellent';
    if (frameAccuracy > 2) syncQuality = 'good';
    if (frameAccuracy > 5) syncQuality = 'fair';
    if (frameAccuracy > 10) syncQuality = 'poor';

    let frameAlignment = 'perfect';
    if (frameAccuracy > 0.5) frameAlignment = 'good';
    if (frameAccuracy > 1) frameAlignment = 'acceptable';
    if (frameAccuracy > 3) frameAlignment = 'poor';

    const audioQuality = lipSyncValidation.overallGrade;
    const lipSyncQuality = lipSyncValidation.accuracy > 0.9 ? 'excellent' :
      lipSyncValidation.accuracy > 0.8 ? 'good' :
        lipSyncValidation.accuracy > 0.7 ? 'fair' : 'poor';

    // Overall quality determination
    const qualityScores = {
      sync: syncQuality === 'excellent' ? 4 : syncQuality === 'good' ? 3 : syncQuality === 'fair' ? 2 : 1,
      frame: frameAlignment === 'perfect' ? 4 : frameAlignment === 'good' ? 3 : frameAlignment === 'acceptable' ? 2 : 1,
      audio: audioQuality === 'excellent' ? 4 : audioQuality === 'good' ? 3 : audioQuality === 'fair' ? 2 : 1,
      lipSync: lipSyncQuality === 'excellent' ? 4 : lipSyncQuality === 'good' ? 3 : lipSyncQuality === 'fair' ? 2 : 1
    };

    const averageScore = (qualityScores.sync + qualityScores.frame + qualityScores.audio + qualityScores.lipSync) / 4;
    const overallQuality = averageScore >= 3.5 ? 'excellent' :
      averageScore >= 2.5 ? 'good' :
        averageScore >= 1.5 ? 'fair' : 'poor';

    const validation = {
      fileSize: outputStats.size,
      durationAccuracy,
      frameAccuracy,
      syncQuality,
      frameAlignment,
      audioQuality,
      lipSyncQuality,
      overallQuality,
      qualityScores,
      averageScore,
      metadata: {
        duration: outputMetadata.duration,
        fps: outputMetadata.fps,
        resolution: `${outputMetadata.width}x${outputMetadata.height}`,
        bitrate: outputMetadata.bitrate || 'unknown'
      },
      validation_timestamp: new Date().toISOString()
    };

    console.log(`[${jobId}] Comprehensive validation completed:`);
    console.log(`[${jobId}]   Duration accuracy: ${(durationAccuracy * 1000).toFixed(2)}ms`);
    console.log(`[${jobId}]   Frame accuracy: ${frameAccuracy.toFixed(4)} frames`);
    console.log(`[${jobId}]   Quality scores: Sync(${qualityScores.sync}) Frame(${qualityScores.frame}) Audio(${qualityScores.audio}) LipSync(${qualityScores.lipSync})`);
    console.log(`[${jobId}]   Overall quality: ${overallQuality} (${averageScore.toFixed(2)}/4.0)`);

    return validation;

  } catch (error) {
    console.error(`[${jobId}] Comprehensive final validation failed:`, error.message);

    // Return minimal validation data
    return {
      fileSize: fs.existsSync(outputPath) ? fs.statSync(outputPath).size : 0,
      durationAccuracy: 999,
      frameAccuracy: 999,
      syncQuality: 'unknown',
      frameAlignment: 'unknown',
      audioQuality: 'unknown',
      lipSyncQuality: 'unknown',
      overallQuality: 'unknown',
      error: error.message,
      validation_timestamp: new Date().toISOString()
    };
  }
};

// ===== HELPER FUNCTIONS =====

// ===== GET ULTRA-PRECISE VIDEO METADATA =====
const getUltraPreciseVideoMetadata = async (videoPath) => {
  return new Promise((resolve, reject) => {
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');
    const command = `ffprobe -v quiet -print_format json -show_streams -show_format "${videoPathFixed}"`;

    exec(command, { timeout: 20000 }, (error, stdout, stderr) => {
      if (error) {
        reject(new Error(`Ultra-precise video metadata extraction failed: ${error.message}`));
        return;
      }

      try {
        const data = JSON.parse(stdout);
        const videoStream = data.streams.find(s => s.codec_type === 'video');

        if (!videoStream) {
          reject(new Error('No video stream found in ultra-precise metadata'));
          return;
        }

        // Parse frame rate with high precision
        let fps = 30; // Default
        if (videoStream.r_frame_rate) {
          const [num, den] = videoStream.r_frame_rate.split('/');
          fps = parseFloat(num) / parseFloat(den);
        }

        const duration = parseFloat(data.format.duration) || 0;
        const bitrate = parseInt(data.format.bit_rate) || 0;

        resolve({
          duration: Math.round(duration * 10000) / 10000, // 4 decimal precision
          fps: Math.round(fps * 1000) / 1000, // 3 decimal precision
          width: videoStream.width || 0,
          height: videoStream.height || 0,
          bitrate: bitrate,
          codec: videoStream.codec_name || 'unknown',
          frameCount: Math.floor(duration * fps)
        });

      } catch (parseError) {
        reject(new Error(`Failed to parse ultra-precise video metadata: ${parseError.message}`));
      }
    });
  });
};

// ===== GET ULTRA-PRECISE AUDIO METADATA =====
const getUltraPreciseAudioMetadata = async (audioPath) => {
  return new Promise((resolve, reject) => {
    const audioPathFixed = path.resolve(audioPath).replace(/\\/g, '/');
    const command = `ffprobe -v quiet -print_format json -show_streams -show_format "${audioPathFixed}"`;

    exec(command, { timeout: 15000 }, (error, stdout, stderr) => {
      if (error) {
        reject(new Error(`Ultra-precise audio metadata extraction failed: ${error.message}`));
        return;
      }

      try {
        const data = JSON.parse(stdout);
        const audioStream = data.streams.find(s => s.codec_type === 'audio');

        if (!audioStream) {
          reject(new Error('No audio stream found in ultra-precise metadata'));
          return;
        }

        const duration = parseFloat(data.format.duration) || 0;
        const bitrate = parseInt(data.format.bit_rate) || parseInt(audioStream.bit_rate) || 0;
        const sampleRate = parseInt(audioStream.sample_rate) || 44100;

        resolve({
          duration: Math.round(duration * 10000) / 10000, // 4 decimal precision
          bitrate: bitrate,
          sampleRate: sampleRate,
          channels: audioStream.channels || 2,
          codec: audioStream.codec_name || 'unknown',
          sampleCount: Math.floor(duration * sampleRate)
        });

      } catch (parseError) {
        reject(new Error(`Failed to parse ultra-precise audio metadata: ${parseError.message}`));
      }
    });
  });
};

// ===== GET ULTRA-PRECISE AUDIO DURATION =====
const getUltraPreciseAudioDuration = async (audioPath) => {
  const metadata = await getUltraPreciseAudioMetadata(audioPath);
  return metadata.duration;
};

// ===== GET ULTRA-PRECISE VIDEO DURATION =====
const getUltraPreciseVideoDuration = async (videoPath) => {
  const metadata = await getUltraPreciseVideoMetadata(videoPath);
  return metadata.duration;
};

// ===== CREATE FALLBACK LIP SYNC REFERENCE =====
const createFallbackLipSyncReference = async (videoPath, jobId) => {
  console.log(`[${jobId}] Creating fallback lip sync reference...`);

  try {
    const videoDuration = await getUltraPreciseVideoDuration(videoPath);
    const segmentDuration = 2.0; // 2-second segments
    const numSegments = Math.ceil(videoDuration / segmentDuration);

    const fallbackSyncPoints = [];

    for (let i = 0; i < numSegments; i++) {
      const timestamp = i * segmentDuration;
      const intensity = 0.5 + Math.random() * 0.3; // Random intensity 0.5-0.8

      fallbackSyncPoints.push({
        timestamp: Math.min(timestamp, videoDuration),
        type: 'speech_segment',
        intensity: intensity,
        confidence: 0.3 // Low confidence for fallback
      });
    }

    return {
      sync_points: fallbackSyncPoints,
      total_points: fallbackSyncPoints.length,
      confidence_level: 'low',
      method: 'fallback_estimate',
      total_duration: videoDuration
    };

  } catch (error) {
    console.error(`[${jobId}] Fallback lip sync reference creation failed:`, error.message);

    // Minimal fallback
    return {
      sync_points: [],
      total_points: 0,
      confidence_level: 'none',
      method: 'minimal_fallback',
      total_duration: 30 // Default assumption
    };
  }
};

// ===== DISCOVER TRANSCRIPT =====
const discoverTranscript = async (jobId) => {
  const transcriptPaths = [
    `./uploads/transcripts/${jobId}_transcript.txt`,
    `./uploads/transcripts/${jobId}_sr_output.json`,
    `./uploads/transcripts/${jobId}.txt`,
    `./uploads/transcription/${jobId}.txt`
  ];

  for (const transcriptPath of transcriptPaths) {
    if (fs.existsSync(transcriptPath)) {
      console.log(`[${jobId}] Found transcript: ${transcriptPath}`);
      return transcriptPath;
    }
  }

  console.warn(`[${jobId}] No transcript file found`);
  return null;
};

// ===== DETERMINE OVERALL SYNC QUALITY =====
const determineOverallSyncQuality = (neuralResults, phonemeValidation, lipSyncValidation) => {
  const qualityScores = [];

  // Neural quality score
  if (neuralResults.sync_quality === 'excellent') qualityScores.push(4);
  else if (neuralResults.sync_quality === 'good') qualityScores.push(3);
  else if (neuralResults.sync_quality === 'fair') qualityScores.push(2);
  else qualityScores.push(1);

  // Phoneme quality score
  if (phonemeValidation) {
    if (phonemeValidation.confidence > 0.8) qualityScores.push(4);
    else if (phonemeValidation.confidence > 0.6) qualityScores.push(3);
    else if (phonemeValidation.confidence > 0.4) qualityScores.push(2);
    else qualityScores.push(1);
  }

  // Lip sync quality score
  if (lipSyncValidation) {
    if (lipSyncValidation.accuracy > 0.8) qualityScores.push(4);
    else if (lipSyncValidation.accuracy > 0.6) qualityScores.push(3);
    else if (lipSyncValidation.accuracy > 0.4) qualityScores.push(2);
    else qualityScores.push(1);
  }

  const averageScore = qualityScores.reduce((a, b) => a + b, 0) / qualityScores.length;

  if (averageScore >= 3.5) return 'excellent';
  if (averageScore >= 2.5) return 'good';
  if (averageScore >= 1.5) return 'fair';
  return 'poor';
};

// ===== VALIDATE PHONEME SYNC =====
const validatePhonemeSync = async (audioPath, wordLevelAlignment, jobId) => {
  console.log(`[${jobId}] Validating phoneme sync...`);

  try {
    if (!wordLevelAlignment.phoneme_timings || wordLevelAlignment.phoneme_timings.length === 0) {
      return { confidence: 0.1, accuracy: 0.1, method: 'no_phonemes' };
    }

    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const lastTiming = wordLevelAlignment.phoneme_timings[wordLevelAlignment.phoneme_timings.length - 1];
    const phonemeDuration = lastTiming.end;

    const durationMatch = Math.abs(audioDuration - phonemeDuration) < 0.5;
    const confidence = durationMatch ? 0.8 : 0.4;

    return {
      confidence,
      accuracy: confidence,
      method: 'phoneme_duration_match',
      audioDuration,
      phonemeDuration,
      durationMatch
    };

  } catch (error) {
    console.error(`[${jobId}] Phoneme sync validation failed:`, error.message);
    return { confidence: 0.1, accuracy: 0.1, method: 'error', error: error.message };
  }
};

// ===== VALIDATE AGAINST LIP SYNC POINTS =====
const validateAgainstLipSyncPoints = async (audioPath, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Validating against lip sync points...`);

  try {
    if (!lipSyncReference.sync_points || lipSyncReference.sync_points.length === 0) {
      return { confidence: 0.1, accuracy: 0.1, method: 'no_sync_points' };
    }

    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const videoDuration = lipSyncReference.total_duration;

    const durationMatch = Math.abs(audioDuration - videoDuration) / videoDuration < 0.05; // 5% tolerance
    const confidence = durationMatch ? 0.7 : 0.3;

    return {
      confidence,
      accuracy: confidence,
      method: 'lip_sync_duration_match',
      audioDuration,
      videoDuration,
      durationMatch
    };

  } catch (error) {
    console.error(`[${jobId}] Lip sync point validation failed:`, error.message);
    return { confidence: 0.1, accuracy: 0.1, method: 'error', error: error.message };
  }
};

// ===== CALCULATE LIP SYNC ACCURACY =====
const calculateLipSyncAccuracy = async (audioPath, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Calculating lip sync accuracy...`);

  try {
    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const referenceDuration = lipSyncReference.total_duration;

    const durationAccuracy = 1 - Math.abs(audioDuration - referenceDuration) / referenceDuration;
    const syncPointsCount = lipSyncReference.sync_points.length;
    const confidenceLevel = lipSyncReference.confidence_level;

    // Calculate match score based on multiple factors
    let matchScore = durationAccuracy * 0.6; // 60% weight to duration
    matchScore += (syncPointsCount / 20) * 0.2; // 20% weight to sync point density
    matchScore += (confidenceLevel === 'high' ? 0.2 : confidenceLevel === 'medium' ? 0.1 : 0.05); // 20% weight to confidence

    matchScore = Math.min(1.0, Math.max(0.0, matchScore));

    const grade = matchScore > 0.9 ? 'excellent' :
      matchScore > 0.8 ? 'good' :
        matchScore > 0.7 ? 'fair' : 'poor';

    return {
      accuracy: durationAccuracy,
      matchScore: matchScore,
      grade: grade,
      confidence: confidenceLevel === 'high' ? 0.9 : confidenceLevel === 'medium' ? 0.7 : 0.5,
      details: {
        audioDuration,
        referenceDuration,
        syncPointsCount,
        confidenceLevel,
        durationDifference: Math.abs(audioDuration - referenceDuration)
      }
    };

  } catch (error) {
    console.error(`[${jobId}] Lip sync accuracy calculation failed:`, error.message);

    return {
      accuracy: 0.1,
      matchScore: 0.1,
      grade: 'poor',
      confidence: 0.1,
      error: error.message
    };
  }
};

// ===== CLEANUP ADVANCED TEMPORARY FILES =====
const cleanupAdvancedTemporaryFiles = async (tempFiles, originalFile, jobId) => {
  console.log(`[${jobId}] Performing advanced cleanup of temporary files...`);

  let cleanedFiles = 0;
  let cleanupErrors = 0;

  for (const tempFile of tempFiles) {
    if (tempFile !== originalFile && fs.existsSync(tempFile)) {
      try {
        const fileStats = fs.statSync(tempFile);
        fs.unlinkSync(tempFile);
        cleanedFiles++;
        console.log(`[${jobId}] Cleaned: ${path.basename(tempFile)} (${Math.round(fileStats.size / 1024)}KB)`);
      } catch (cleanupError) {
        cleanupErrors++;
        console.warn(`[${jobId}] Failed to cleanup ${path.basename(tempFile)}:`, cleanupError.message);
      }
    }
  }

  console.log(`[${jobId}] Advanced cleanup completed: ${cleanedFiles} files removed, ${cleanupErrors} errors`);

  // Optional: Cleanup empty directories
  const tempDirs = [
    './uploads/temp_audio',
    './uploads/sync',
    './uploads/neural_align'
  ];

  for (const tempDir of tempDirs) {
    try {
      if (fs.existsSync(tempDir)) {
        const files = fs.readdirSync(tempDir);
        if (files.length === 0) {
          fs.rmdirSync(tempDir);
          console.log(`[${jobId}] Removed empty directory: ${tempDir}`);
        }
      }
    } catch (dirCleanupError) {
      console.warn(`[${jobId}] Failed to cleanup directory ${tempDir}:`, dirCleanupError.message);
    }
  }
};

// ===== LEGACY FUNCTIONS FOR COMPATIBILITY =====

export const discoverJobFiles = discoverJobFilesAdvanced;

export const validateAudioVideoDurations = async (videoPath, audioPath, jobId) => {
  const frameLevelValidation = await performFrameLevelDurationValidation(videoPath, audioPath, null, null, jobId);

  return {
    videoDuration: frameLevelValidation.videoDuration,
    audioDuration: frameLevelValidation.audioDuration,
    durationDifference: frameLevelValidation.durationDifference,
    durationsMatch: frameLevelValidation.syncQuality !== 'poor',
    tolerance: 1.5,
    severity: frameLevelValidation.syncQuality === 'poor' ? 'critical' :
      frameLevelValidation.syncQuality === 'fair' ? 'warning' : 'acceptable'
  };
};

export const correctAudioDurationMismatch = async (audioPath, videoPath, durationValidation, jobId) => {
  console.log(`[${jobId}] Using enhanced real-time sync adjustment for duration correction...`);

  const frameLevelValidation = {
    videoDuration: durationValidation.videoDuration,
    audioDuration: durationValidation.audioDuration,
    durationDifference: durationValidation.durationDifference,
    frameAccuracy: durationValidation.durationDifference / (1 / 30), // Assume 30fps
    frameDuration: 1 / 30,
    fps: 30,
    syncQuality: durationValidation.severity === 'critical' ? 'poor' :
      durationValidation.severity === 'warning' ? 'fair' : 'good',
    requiresAdjustment: !durationValidation.durationsMatch,
    adjustmentStrategy: 'fine_tuning'
  };

  return await performRealTimeSyncAdjustment(audioPath, videoPath, frameLevelValidation, null, null, jobId);
};

export const getMediaDuration = getUltraPreciseVideoDuration;

export const assembleVideoWithAudioOnly = async (jobId) => {
  console.log(`[${jobId}] Using enhanced assembly for audio-only processing...`);
  return await assembleVideoWithCaptions(jobId, null, null);
};

// ===== CONTINUATION OF videoService.js =====

export const getVideoInfo = async (videoPath, jobId) => {
  try {
    const metadata = await getUltraPreciseVideoMetadata(videoPath);
    const audioMetadata = await getUltraPreciseAudioMetadata(videoPath).catch(() => ({ channels: 0, codec: 'none' }));

    return {
      duration: metadata.duration,
      size: fs.statSync(videoPath).size,
      bitrate: metadata.bitrate,
      fps: metadata.fps,
      resolution: `${metadata.width}x${metadata.height}`,
      videoCodec: metadata.codec,
      audioChannels: audioMetadata.channels,
      audioCodec: audioMetadata.codec,
      frameCount: metadata.frameCount,
      format: path.extname(videoPath).toLowerCase(),
      hasVideo: metadata.width > 0 && metadata.height > 0,
      hasAudio: audioMetadata.channels > 0,
      aspectRatio: metadata.width / metadata.height,
      isPortrait: metadata.height > metadata.width,
      quality: metadata.width >= 1920 ? 'HD' : metadata.width >= 1280 ? 'HD Ready' : 'SD',
      info: {
        created: fs.statSync(videoPath).birthtime,
        modified: fs.statSync(videoPath).mtime,
        sizeFormatted: formatFileSize(fs.statSync(videoPath).size),
        durationFormatted: formatDuration(metadata.duration)
      }
    };

  } catch (error) {
    console.error(`[${jobId}] Video info extraction failed:`, error.message);

    // Return minimal info with file stats only
    const stats = fs.existsSync(videoPath) ? fs.statSync(videoPath) : null;
    return {
      duration: 0,
      size: stats ? stats.size : 0,
      bitrate: 0,
      fps: 0,
      resolution: '0x0',
      videoCodec: 'unknown',
      audioChannels: 0,
      audioCodec: 'unknown',
      frameCount: 0,
      format: path.extname(videoPath).toLowerCase(),
      hasVideo: false,
      hasAudio: false,
      aspectRatio: 0,
      isPortrait: false,
      quality: 'unknown',
      error: error.message,
      info: stats ? {
        created: stats.birthtime,
        modified: stats.mtime,
        sizeFormatted: formatFileSize(stats.size),
        durationFormatted: '0:00'
      } : null
    };
  }
};

// ===== UTILITY FUNCTIONS =====

// Format file size in human readable format
const formatFileSize = (bytes) => {
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
  if (bytes === 0) return '0 Bytes';

  const i = Math.floor(Math.log(bytes) / Math.log(1024));
  return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
};

// Format duration in MM:SS or HH:MM:SS format
const formatDuration = (seconds) => {
  if (isNaN(seconds) || seconds <= 0) return '0:00';

  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);

  if (hours > 0) {
    return `${hours}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  } else {
    return `${minutes}:${secs.toString().padStart(2, '0')}`;
  }
};

// ===== ENHANCED SUBTITLE PROCESSING =====

export const generateSubtitles = async (translation, jobId, targetLanguage, outputFormat = 'vtt') => {
  try {
    console.log(`[${jobId}] Generating subtitles in ${outputFormat.toUpperCase()} format for ${targetLanguage}...`);

    if (!translation || !translation.segments || translation.segments.length === 0) {
      throw new Error('No translation segments available for subtitle generation');
    }

    const outputDir = './uploads/captions';
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    const baseFileName = `${jobId}_captions`;
    const vttPath = path.join(outputDir, `${baseFileName}.vtt`);
    const srtPath = path.join(outputDir, `${baseFileName}.srt`);

    const segments = translation.segments;

    // ===== GENERATE WEBVTT FORMAT =====
    let vttContent = 'WEBVTT\n\n';

    segments.forEach((segment, index) => {
      if (!segment.text || segment.text.trim().length === 0) return;

      const start = formatTimestampVTT(segment.start || (index * 2.5));
      const end = formatTimestampVTT(segment.end || ((index + 1) * 2.5));

      vttContent += `${index + 1}\n`;
      vttContent += `${start} --> ${end}\n`;
      vttContent += `${segment.text.trim()}\n\n`;
    });

    fs.writeFileSync(vttPath, vttContent, 'utf8');

    // ===== GENERATE SRT FORMAT =====
    let srtContent = '';

    segments.forEach((segment, index) => {
      if (!segment.text || segment.text.trim().length === 0) return;

      const start = formatTimestampSRT(segment.start || (index * 2.5));
      const end = formatTimestampSRT(segment.end || ((index + 1) * 2.5));

      srtContent += `${index + 1}\n`;
      srtContent += `${start} --> ${end}\n`;
      srtContent += `${segment.text.trim()}\n\n`;
    });

    fs.writeFileSync(srtPath, srtContent, 'utf8');

    console.log(`[${jobId}] ‚úÖ Subtitles generated successfully:`);
    console.log(`[${jobId}]   WebVTT: ${vttPath} (${fs.statSync(vttPath).size} bytes)`);
    console.log(`[${jobId}]   SRT: ${srtPath} (${fs.statSync(srtPath).size} bytes)`);
    console.log(`[${jobId}]   Segments: ${segments.length}`);
    console.log(`[${jobId}]   Language: ${targetLanguage}`);

    return {
      vttPath,
      srtPath,
      segmentCount: segments.length,
      language: targetLanguage,
      vttSize: fs.statSync(vttPath).size,
      srtSize: fs.statSync(srtPath).size,
      success: true
    };

  } catch (error) {
    console.error(`[${jobId}] Subtitle generation failed:`, error.message);
    throw error;
  }
};

// Format timestamp for WebVTT format (HH:MM:SS.mmm)
const formatTimestampVTT = (seconds) => {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const milliseconds = Math.floor((seconds % 1) * 1000);

  return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${milliseconds.toString().padStart(3, '0')}`;
};

// Format timestamp for SRT format (HH:MM:SS,mmm)
const formatTimestampSRT = (seconds) => {
  const timestamp = formatTimestampVTT(seconds);
  return timestamp.replace('.', ','); // SRT uses comma instead of dot
};

// ===== ADVANCED VIDEO PROCESSING FUNCTIONS =====

export const extractVideoThumbnails = async (videoPath, jobId, count = 5) => {
  console.log(`[${jobId}] Extracting ${count} thumbnails from video...`);

  try {
    const outputDir = `./uploads/thumbnails/${jobId}`;
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    const videoMetadata = await getUltraPreciseVideoMetadata(videoPath);
    const duration = videoMetadata.duration;
    const interval = duration / (count + 1); // Evenly spaced thumbnails

    const thumbnailPaths = [];
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');

    for (let i = 1; i <= count; i++) {
      const timestamp = i * interval;
      const outputPath = path.join(outputDir, `thumbnail_${i}.jpg`);
      const outputPathFixed = path.resolve(outputPath).replace(/\\/g, '/');

      const command = `ffmpeg -i "${videoPathFixed}" -ss ${timestamp.toFixed(2)} -vframes 1 -vf "scale=320:180" -y "${outputPathFixed}"`;

      try {
        await execAsync(command);

        if (fs.existsSync(outputPath)) {
          thumbnailPaths.push({
            path: outputPath,
            timestamp: timestamp,
            index: i,
            size: fs.statSync(outputPath).size
          });
        }
      } catch (thumbError) {
        console.warn(`[${jobId}] Failed to generate thumbnail ${i}:`, thumbError.message);
      }
    }

    console.log(`[${jobId}] ‚úÖ Generated ${thumbnailPaths.length}/${count} thumbnails`);

    return {
      thumbnails: thumbnailPaths,
      totalGenerated: thumbnailPaths.length,
      totalRequested: count,
      outputDirectory: outputDir,
      videoDuration: duration
    };

  } catch (error) {
    console.error(`[${jobId}] Thumbnail extraction failed:`, error.message);
    throw error;
  }
};

export const analyzeVideoQuality = async (videoPath, jobId) => {
  console.log(`[${jobId}] Analyzing video quality metrics...`);

  try {
    const metadata = await getUltraPreciseVideoMetadata(videoPath);
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');

    // Extract quality metrics using ffprobe
    const qualityCommand = `ffprobe -v quiet -select_streams v:0 -show_entries frame=pkt_pts_time,pict_type -of csv=p=0 "${videoPathFixed}" | head -100`;

    let frameAnalysis = { iFrames: 0, pFrames: 0, bFrames: 0, totalFrames: 0 };

    try {
      const { stdout } = await execAsync(qualityCommand);
      const frames = stdout.trim().split('\n').filter(line => line.trim());

      frames.forEach(frame => {
        const [timestamp, type] = frame.split(',');
        frameAnalysis.totalFrames++;

        if (type === 'I') frameAnalysis.iFrames++;
        else if (type === 'P') frameAnalysis.pFrames++;
        else if (type === 'B') frameAnalysis.bFrames++;
      });
    } catch (frameError) {
      console.warn(`[${jobId}] Frame analysis failed:`, frameError.message);
    }

    // Calculate quality scores
    const resolutionScore = calculateResolutionScore(metadata.width, metadata.height);
    const bitrateScore = calculateBitrateScore(metadata.bitrate, metadata.width, metadata.height);
    const frameRateScore = calculateFrameRateScore(metadata.fps);

    const overallScore = (resolutionScore + bitrateScore + frameRateScore) / 3;

    const qualityGrade = overallScore >= 8 ? 'Excellent' :
      overallScore >= 6 ? 'Good' :
        overallScore >= 4 ? 'Fair' : 'Poor';

    const analysis = {
      resolution: {
        width: metadata.width,
        height: metadata.height,
        pixels: metadata.width * metadata.height,
        quality: getResolutionQuality(metadata.width, metadata.height),
        score: resolutionScore
      },
      bitrate: {
        value: metadata.bitrate,
        formatted: formatBitrate(metadata.bitrate),
        score: bitrateScore,
        adequacy: getBitrateAdequacy(metadata.bitrate, metadata.width, metadata.height)
      },
      frameRate: {
        fps: metadata.fps,
        score: frameRateScore,
        category: getFrameRateCategory(metadata.fps)
      },
      frames: frameAnalysis,
      overall: {
        score: overallScore,
        grade: qualityGrade,
        recommendations: generateQualityRecommendations(metadata, overallScore)
      },
      technical: {
        codec: metadata.codec,
        duration: metadata.duration,
        frameCount: metadata.frameCount,
        aspectRatio: (metadata.width / metadata.height).toFixed(2),
        isHDR: false, // Would require more advanced analysis
        colorSpace: 'unknown' // Would require more advanced analysis
      }
    };

    console.log(`[${jobId}] ‚úÖ Video quality analysis completed:`);
    console.log(`[${jobId}]   Overall grade: ${qualityGrade} (${overallScore.toFixed(1)}/10)`);
    console.log(`[${jobId}]   Resolution: ${metadata.width}x${metadata.height} (${analysis.resolution.quality})`);
    console.log(`[${jobId}]   Bitrate: ${analysis.bitrate.formatted} (${analysis.bitrate.adequacy})`);
    console.log(`[${jobId}]   Frame rate: ${metadata.fps}fps (${analysis.frameRate.category})`);

    return analysis;

  } catch (error) {
    console.error(`[${jobId}] Video quality analysis failed:`, error.message);
    throw error;
  }
};

// ===== QUALITY CALCULATION HELPER FUNCTIONS =====

const calculateResolutionScore = (width, height) => {
  const pixels = width * height;

  if (pixels >= 8294400) return 10; // 4K+ (3840x2160)
  if (pixels >= 2073600) return 9;  // 1440p (2560x1440)
  if (pixels >= 2073600) return 8;  // 1080p (1920x1080)
  if (pixels >= 921600) return 6;   // 720p (1280x720)
  if (pixels >= 409920) return 4;   // 480p (854x480)
  if (pixels >= 230400) return 3;   // 360p (640x360)
  return 2; // Below 360p
};

const calculateBitrateScore = (bitrate, width, height) => {
  if (!bitrate) return 5; // Unknown bitrate

  const pixels = width * height;
  const bitsPerPixel = bitrate / pixels;

  // Optimal bits per pixel for different resolutions
  let optimalBPP = 0.1; // Default

  if (pixels >= 8294400) optimalBPP = 0.05; // 4K
  else if (pixels >= 2073600) optimalBPP = 0.07; // 1440p
  else if (pixels >= 2073600) optimalBPP = 0.1; // 1080p
  else if (pixels >= 921600) optimalBPP = 0.15; // 720p
  else optimalBPP = 0.2; // Lower resolutions

  const ratio = bitsPerPixel / optimalBPP;

  if (ratio >= 1.5) return 10; // High bitrate
  if (ratio >= 1.0) return 8;  // Good bitrate
  if (ratio >= 0.7) return 6;  // Adequate bitrate
  if (ratio >= 0.5) return 4;  // Low bitrate
  return 2; // Very low bitrate
};

const calculateFrameRateScore = (fps) => {
  if (fps >= 60) return 10; // High frame rate
  if (fps >= 30) return 8;  // Standard frame rate
  if (fps >= 24) return 6;  // Cinematic frame rate
  if (fps >= 15) return 4;  // Low frame rate
  return 2; // Very low frame rate
};

const getResolutionQuality = (width, height) => {
  const pixels = width * height;

  if (pixels >= 8294400) return '4K Ultra HD';
  if (pixels >= 2073600) return 'Quad HD (1440p)';
  if (pixels >= 2073600) return 'Full HD (1080p)';
  if (pixels >= 921600) return 'HD (720p)';
  if (pixels >= 409920) return 'SD (480p)';
  if (pixels >= 230400) return 'Low (360p)';
  return 'Very Low';
};

const getBitrateAdequacy = (bitrate, width, height) => {
  if (!bitrate) return 'Unknown';

  const mbps = bitrate / 1000000;
  const pixels = width * height;

  let recommended = 5; // Default 5 Mbps for HD

  if (pixels >= 8294400) recommended = 25; // 4K
  else if (pixels >= 2073600) recommended = 15; // 1440p
  else if (pixels >= 2073600) recommended = 8; // 1080p
  else if (pixels >= 921600) recommended = 5; // 720p
  else recommended = 2; // SD

  const ratio = mbps / recommended;

  if (ratio >= 1.5) return 'Excellent';
  if (ratio >= 1.0) return 'Good';
  if (ratio >= 0.7) return 'Adequate';
  if (ratio >= 0.5) return 'Low';
  return 'Very Low';
};

const getFrameRateCategory = (fps) => {
  if (fps >= 60) return 'High Frame Rate';
  if (fps >= 30) return 'Standard';
  if (fps >= 24) return 'Cinematic';
  if (fps >= 15) return 'Low';
  return 'Very Low';
};

const formatBitrate = (bitrate) => {
  if (!bitrate) return 'Unknown';

  const mbps = bitrate / 1000000;

  if (mbps >= 1) {
    return `${mbps.toFixed(1)} Mbps`;
  } else {
    const kbps = bitrate / 1000;
    return `${kbps.toFixed(0)} kbps`;
  }
};

const generateQualityRecommendations = (metadata, overallScore) => {
  const recommendations = [];

  if (metadata.width < 1280) {
    recommendations.push('Consider using higher resolution source material (720p minimum recommended)');
  }

  if (metadata.fps < 24) {
    recommendations.push('Frame rate appears low - consider 24fps minimum for smooth playback');
  }

  if (metadata.bitrate && metadata.bitrate < 2000000) {
    recommendations.push('Bitrate may be too low for optimal quality - consider increasing encoding bitrate');
  }

  if (overallScore < 6) {
    recommendations.push('Overall video quality could be improved - consider re-encoding with higher quality settings');
  }

  if (recommendations.length === 0) {
    recommendations.push('Video quality appears to be good - no immediate improvements needed');
  }

  return recommendations;
};

// ===== BATCH PROCESSING FUNCTIONS =====

export const batchProcessVideos = async (jobIds, processingOptions = {}) => {
  console.log(`Starting batch processing for ${jobIds.length} videos...`);

  const results = {
    total: jobIds.length,
    successful: 0,
    failed: 0,
    details: [],
    startTime: Date.now(),
    endTime: null,
    processingTime: 0
  };

  for (let i = 0; i < jobIds.length; i++) {
    const jobId = jobIds[i];
    const progress = `${i + 1}/${jobIds.length}`;

    console.log(`[BATCH] Processing ${progress}: ${jobId}`);

    try {
      const jobResult = await assembleVideoWithCaptions(jobId, null, null);

      results.successful++;
      results.details.push({
        jobId,
        status: 'success',
        outputPath: jobResult.outputPath,
        processingTime: jobResult.processingStats?.totalProcessingTime || 0,
        quality: jobResult.validation?.overallQuality || 'unknown'
      });

      console.log(`[BATCH] ‚úÖ ${progress} completed: ${jobId}`);

    } catch (error) {
      results.failed++;
      results.details.push({
        jobId,
        status: 'failed',
        error: error.message,
        timestamp: new Date().toISOString()
      });

      console.error(`[BATCH] ‚ùå ${progress} failed: ${jobId} - ${error.message}`);
    }

    // Small delay between jobs to prevent overwhelming the system
    if (i < jobIds.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }

  results.endTime = Date.now();
  results.processingTime = results.endTime - results.startTime;

  console.log(`[BATCH] ‚úÖ Batch processing completed:`);
  console.log(`[BATCH]   Total: ${results.total}`);
  console.log(`[BATCH]   Successful: ${results.successful}`);
  console.log(`[BATCH]   Failed: ${results.failed}`);
  console.log(`[BATCH]   Processing time: ${formatDuration(results.processingTime / 1000)}`);

  return results;
};

// ===== ERROR RECOVERY FUNCTIONS =====

export const recoverFromProcessingError = async (jobId, lastKnownState = null) => {
  console.log(`[${jobId}] Attempting error recovery...`);

  try {
    // Discover what files we have available
    const filePaths = await discoverJobFilesAdvanced(jobId);

    const recovery = {
      jobId,
      recoveryAttempted: true,
      availableFiles: {
        originalVideo: !!filePaths.originalVideo,
        translatedAudio: !!filePaths.translatedAudio,
        captions: !!filePaths.captions,
        transcript: !!filePaths.transcript
      },
      recoveryStrategy: null,
      recoveryResult: null
    };

    // Determine recovery strategy
    if (filePaths.originalVideo && filePaths.translatedAudio) {
      recovery.recoveryStrategy = 'full_assembly_retry';
      console.log(`[${jobId}] Recovery strategy: Full assembly retry`);

      try {
        recovery.recoveryResult = await assembleVideoWithCaptions(jobId, null, null);
        recovery.recoverySuccessful = true;

        console.log(`[${jobId}] ‚úÖ Full recovery successful`);

      } catch (assemblyError) {
        recovery.recoverySuccessful = false;
        recovery.recoveryError = assemblyError.message;

        // Try simpler assembly without advanced features
        console.log(`[${jobId}] Trying simplified assembly...`);

        try {
          recovery.recoveryResult = await performSimplifiedAssembly(
            filePaths.originalVideo,
            filePaths.translatedAudio,
            filePaths.captions,
            jobId
          );
          recovery.recoverySuccessful = true;
          recovery.recoveryStrategy = 'simplified_assembly';

          console.log(`[${jobId}] ‚úÖ Simplified recovery successful`);

        } catch (simplifiedError) {
          recovery.recoverySuccessful = false;
          recovery.recoveryError = simplifiedError.message;
          console.error(`[${jobId}] ‚ùå Both recovery methods failed`);
        }
      }

    } else {
      recovery.recoveryStrategy = 'insufficient_files';
      recovery.recoverySuccessful = false;
      recovery.recoveryError = 'Required files not available for recovery';

      console.error(`[${jobId}] ‚ùå Recovery impossible - missing required files`);
    }

    return recovery;

  } catch (error) {
    console.error(`[${jobId}] Recovery attempt failed:`, error.message);

    return {
      jobId,
      recoveryAttempted: true,
      recoverySuccessful: false,
      recoveryError: error.message,
      availableFiles: {},
      recoveryStrategy: 'error'
    };
  }
};

// ===== SIMPLIFIED ASSEMBLY FOR ERROR RECOVERY =====
const performSimplifiedAssembly = async (videoPath, audioPath, captionPath, jobId) => {
  console.log(`[${jobId}] Performing simplified assembly for error recovery...`);

  const outputPath = `./uploads/processed/${jobId}_final_recovered.mp4`;

  // Ensure output directory exists
  const outputDir = path.dirname(outputPath);
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  return new Promise((resolve, reject) => {
    // ‚úÖ FIXED: Simple assembly with proper path handling and subtitle embedding
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');
    const audioPathFixed = path.resolve(audioPath).replace(/\\/g, '/');
    const outputPathFixed = path.resolve(outputPath).replace(/\\/g, '/');

    let command = [
      'ffmpeg',
      '-i', `"${videoPathFixed}"`,
      '-i', `"${audioPathFixed}"`
    ];

    // Add subtitle filter if captions exist (FIXED for Windows)
    if (captionPath && fs.existsSync(captionPath)) {
      const captionPathForFFmpeg = path.resolve(captionPath).replace(/\\/g, '/');
      // Use hex format without ampersands
      command.push('-vf', `"scale=-2:720,fps=50,subtitles='${captionPathForFFmpeg}':force_style='FontSize=16,PrimaryColour=0xFFFFFF,OutlineColour=0x000000,Outline=2'"`);
    }


    // Simple encoding options
    command = command.concat([
      '-c:v', 'libx264',
      '-c:a', 'aac',
      '-preset', 'fast',
      '-crf', '25',
      '-y', `"${outputPathFixed}"`
    ]);

    const ffmpegCommand = command.join(' ');

    console.log(`[${jobId}] Simplified assembly command: ${ffmpegCommand.substring(0, 150)}...`);

    exec(ffmpegCommand, {
      maxBuffer: 1024 * 1024 * 100, // 100MB buffer
      timeout: 300000 // 5 minutes
    }, (error, stdout, stderr) => {
      if (error) {
        console.error(`[${jobId}] Simplified assembly failed:`, error.message);
        reject(error);
        return;
      }

      if (!fs.existsSync(outputPath)) {
        reject(new Error('Simplified assembly completed but output file not found'));
        return;
      }

      const outputStats = fs.statSync(outputPath);

      if (outputStats.size < 50000) {
        reject(new Error(`Simplified assembly output too small: ${outputStats.size} bytes`));
        return;
      }

      console.log(`[${jobId}] ‚úÖ Simplified assembly completed: ${Math.round(outputStats.size / 1024 / 1024)}MB`);

      resolve({
        outputPath,
        fileSize: outputStats.size,
        method: 'simplified_recovery',
        timestamp: new Date().toISOString()
      });
    });
  });
};

// ===== SYSTEM HEALTH AND MONITORING =====

export const getProcessingSystemHealth = async () => {
  console.log('Checking video processing system health...');

  const health = {
    timestamp: new Date().toISOString(),
    ffmpeg: { available: false, version: null },
    diskSpace: { available: 0, total: 0, percentUsed: 0 },
    directories: {},
    processing: {
      activeJobs: 0,
      queuedJobs: 0,
      failedJobs: 0
    },
    recommendations: []
  };

  try {
    // Check FFmpeg availability
    try {
      const { stdout } = await execAsync('ffmpeg -version');
      health.ffmpeg.available = true;
      health.ffmpeg.version = stdout.split('\n')[0].match(/ffmpeg version ([^\s]+)/)?.[1] || 'unknown';
    } catch (ffmpegError) {
      health.ffmpeg.available = false;
      health.recommendations.push('FFmpeg not found - install FFmpeg for video processing');
    }

    // Check critical directories
    const criticalDirs = [
      './uploads',
      './uploads/originals',
      './uploads/processed',
      './uploads/translated_audio',
      './uploads/captions',
      './uploads/transcripts'
    ];

    for (const dir of criticalDirs) {
      health.directories[dir] = {
        exists: fs.existsSync(dir),
        writable: false,
        fileCount: 0
      };

      if (health.directories[dir].exists) {
        try {
          // Test write access
          const testFile = path.join(dir, '.health_test');
          fs.writeFileSync(testFile, 'test');
          fs.unlinkSync(testFile);
          health.directories[dir].writable = true;

          // Count files
          const files = fs.readdirSync(dir);
          health.directories[dir].fileCount = files.length;

        } catch (accessError) {
          health.directories[dir].writable = false;
          health.recommendations.push(`Directory ${dir} is not writable`);
        }
      } else {
        health.recommendations.push(`Critical directory missing: ${dir}`);
      }
    }

    // Check disk space (simplified - would need platform-specific implementation for accuracy)
    try {
      const uploadsDir = './uploads';
      if (fs.existsSync(uploadsDir)) {
        const stats = fs.statSync(uploadsDir);
        // This is a simplified approach - real disk space checking would need platform-specific code
        health.diskSpace.available = 1000000000; // Placeholder: 1GB
        health.diskSpace.total = 10000000000; // Placeholder: 10GB
        health.diskSpace.percentUsed = 10; // Placeholder: 10%
      }
    } catch (diskError) {
      health.recommendations.push('Unable to check disk space');
    }

    // Add general recommendations based on health
    if (!health.ffmpeg.available) {
      health.recommendations.push('Install FFmpeg: https://ffmpeg.org/download.html');
    }

    if (health.diskSpace.percentUsed > 90) {
      health.recommendations.push('Disk space is running low - consider cleanup');
    }

    const missingDirs = Object.entries(health.directories).filter(([dir, info]) => !info.exists);
    if (missingDirs.length > 0) {
      health.recommendations.push('Create missing directories or run system initialization');
    }

    if (health.recommendations.length === 0) {
      health.recommendations.push('System appears healthy - no issues detected');
    }

    console.log('‚úÖ System health check completed');
    console.log(`   FFmpeg: ${health.ffmpeg.available ? '‚úÖ Available' : '‚ùå Missing'}`);
    console.log(`   Directories: ${Object.values(health.directories).filter(d => d.exists).length}/${Object.keys(health.directories).length} OK`);
    console.log(`   Recommendations: ${health.recommendations.length}`);

    return health;

  } catch (error) {
    console.error('System health check failed:', error.message);

    health.error = error.message;
    health.recommendations.push('System health check encountered errors - manual inspection recommended');

    return health;
  }
};


export const resumeProcessing = async (jobId, fromStep = 1) => {
  console.log(`[${jobId}] Resuming processing from step ${fromStep}...`);
  return await assembleVideoWithCaptions(jobId, null, null);
};



// ===== EXPORT ALL FUNCTIONS =====
export default {
  // Main processing functions
  assembleVideoWithCaptions,
  assembleVideoWithAudioOnly,

  // File discovery and validation
  discoverJobFiles: discoverJobFilesAdvanced,
  validateAudioVideoDurations,
  correctAudioDurationMismatch,

  // Media information and analysis
  getVideoInfo,
  getMediaDuration,
  analyzeVideoQuality,
  extractVideoThumbnails,

  // Subtitle and caption functions
  generateSubtitles,

  // Batch processing and error recovery
  batchProcessVideos,
  recoverFromProcessingError,

  // System health and monitoring
  getProcessingSystemHealth,

  // Utility functions
  formatFileSize,
  formatDuration,
  formatTimestampVTT,
  formatTimestampSRT,
  resumeProcessing,           // Add this
  escapeSubtitlePath,
  generateAccurateCaptions 
};
