// services/videoService.js - FIXED SUBTITLE EMBEDDING IN FFMPEG COMMAND

import ffmpeg from 'fluent-ffmpeg';
import ffmpegStatic from 'ffmpeg-static';
import fs from 'fs';
import path from 'path';
import { exec } from 'child_process';
import { promisify } from 'util';
import { extractAudio, extractAudioForcedAlignment, replaceAudioInVideo } from './audioService.js';
import { transcribeAudio } from './transcriptionService.js';
import { translateText } from './translationService.js';
import { generateTTS } from './ttsService.js';
import { 
  detectAudioVideoSync,
  correctAudioSync,
  neuralAudioAlignment,
  adaptiveSyncCorrection
} from './neuralSyncService.js';
import {
  analyzeLipMovements,
  extractLipSyncReference,
  validateAnalysisQuality
} from './lipSyncAnalyzer.js';
import {
  calculateSpeechDuration,
  optimizeSpeechRateForTTS
} from './durationAwareTranslation.js';
import { validateTranslationQuality } from './validationService.js';
import lipSyncAnalyzer from './lipSyncAnalyzer.js';
import { spawn } from 'child_process';


const escapeSubtitlePath = (windowsPath) => {
  return windowsPath
    .replace(/\\/g, '/')  // Convert backslashes to forward slashes
    .replace(/'/g, "\\'") // Escape single quotes only
    .replace(/:/g, '\\:'); // Escape colons for filter syntax
};


const execAsync = promisify(exec);
ffmpeg.setFfmpegPath(ffmpegStatic);

// In videoService.js
// Replace your entire existing 'assembleVideoWithCaptions' function with this complete version.

export const assembleVideoWithCaptions = async (jobId, alignmentData = null, lipSyncData = null) => {
  return new Promise(async (resolve, reject) => {
    try {
      console.log(`[${jobId}] Starting enhanced video assembly with frame-level audio-video alignment and real-time sync...`);

      // ===== DISCOVER FILES WITH ADVANCED SEARCH =====
      const filePaths = await discoverJobFilesAdvanced(jobId);

      if (!filePaths.originalVideo) {
        throw new Error(`Original video file not found for job: ${jobId}`);
      }

      const originalVideoPath = filePaths.originalVideo;
      const translatedAudioPath = filePaths.translatedAudio || `./uploads/translated_audio/${jobId}_translated.wav`;
      const outputVideoPath = `./uploads/processed/${jobId}_final.mp4`;

      console.log(`[${jobId}] üîç ADVANCED FILE DISCOVERY SUMMARY:`);
      console.log(`[${jobId}]   Video: ${filePaths.originalVideo ? '‚úÖ FOUND' : '‚ùå MISSING'}`);
      console.log(`[${jobId}]   Audio: ${filePaths.translatedAudio ? '‚úÖ FOUND' : '‚ùå MISSING'}`);
      console.log(`[${jobId}]   Captions: ${filePaths.captions ? '‚úÖ FOUND' : '‚ö†Ô∏è WILL GENERATE'}`);
      console.log(`[${jobId}]   Transcript: ${filePaths.transcript ? '‚úÖ FOUND' : '‚ö†Ô∏è OPTIONAL'}`);
      console.log(`[${jobId}]   Alignment: ${alignmentData ? '‚úÖ AVAILABLE' : '‚ö†Ô∏è WILL GENERATE'}`);
      console.log(`[${jobId}]   Lip Sync: ${lipSyncData ? '‚úÖ AVAILABLE' : '‚ö†Ô∏è WILL ANALYZE'}`);

      if (!fs.existsSync(originalVideoPath)) {
        throw new Error(`Original video file not found: ${originalVideoPath}`);
      }
      if (!fs.existsSync(translatedAudioPath)) {
        throw new Error(`Translated audio file not found: ${translatedAudioPath}`);
      }

      // ===== CREATE PROCESSED DIRECTORY =====
      const processedDir = './uploads/processed/';
      if (!fs.existsSync(processedDir)) {
        fs.mkdirSync(processedDir, { recursive: true });
        console.log(`[${jobId}] Created processed directory`);
      }

      // ===== STEP 1: COMPREHENSIVE LIP SYNC ANALYSIS =====
      console.log(`[${jobId}] Step 1/8: Comprehensive lip sync analysis...`);
      let lipSyncReference = lipSyncData;
      if (!lipSyncReference) {
        // ... (Your existing lip sync analysis logic is fine here)
      }

      // ===== STEP 2: VALIDATE PRE-GENERATED WORD ALIGNMENT (THE CORRECTED LOGIC) =====
      console.log(`[${jobId}] Step 2/8: Validating pre-generated word-level alignment...`);
      if (!alignmentData || !alignmentData.forced_alignment_result || alignmentData.forced_alignment_result.phoneme_timings.length === 0) {
        throw new Error("Alignment data was not provided or is invalid. This indicates the alignment step in the main pipeline failed.");
      }
      const phonemeAlignment = alignmentData.forced_alignment_result;
      const alignmentQuality = alignmentData.alignment_quality;
      console.log(`[${jobId}] ‚úÖ Word-level alignment data is valid and available:`);
      console.log(`[${jobId}]   Quality: ${alignmentQuality}`);
      console.log(`[${jobId}]   Word timings available: ${phonemeAlignment.phoneme_timings.length}`);

      // ===== STEP 3: FRAME-LEVEL DURATION VALIDATION =====
      console.log(`[${jobId}] Step 3/8: Frame-level duration validation with precision timing...`);
      const frameLevelValidation = await performFrameLevelDurationValidation(
        originalVideoPath,
        translatedAudioPath,
        lipSyncReference,
        phonemeAlignment,
        jobId
      );

      // ===== STEP 4: REAL-TIME SYNC ADJUSTMENT =====
      console.log(`[${jobId}] Step 4/8: Real-time sync adjustment with frame-level precision...`);
      let realTimeSyncedAudioPath = translatedAudioPath;
      if (frameLevelValidation.requiresAdjustment) {
        realTimeSyncedAudioPath = await performRealTimeSyncAdjustment(
          translatedAudioPath,
          originalVideoPath,
          frameLevelValidation,
          lipSyncReference,
          phonemeAlignment,
          jobId
        );
      }

      // ===== STEP 5: ADVANCED NEURAL SYNC VALIDATION =====
      console.log(`[${jobId}] Step 5/8: Advanced neural sync validation...`);
      const neuralSyncResults = await performAdvancedNeuralSyncValidation(
        originalVideoPath,
        realTimeSyncedAudioPath,
        lipSyncReference,
        phonemeAlignment,
        jobId
      );
      let neuralCorrectedAudioPath = realTimeSyncedAudioPath;
      if (neuralSyncResults.requiresCorrection) {
        neuralCorrectedAudioPath = await applyNeuralSyncCorrection(
          realTimeSyncedAudioPath,
          originalVideoPath,
          neuralSyncResults,
          lipSyncReference,
          jobId
        );
      }

      // ===== STEP 6: LIP SYNC VALIDATION =====
      console.log(`[${jobId}] Step 6/8: Final lip sync validation...`);
      const lipSyncValidation = await validateFinalLipSync(
        originalVideoPath,
        neuralCorrectedAudioPath,
        lipSyncReference,
        phonemeAlignment,
        jobId
      );

// Step 6.5/8: Load translation data and generate accurate captions
console.log(`[${jobId}] Step 6.5/8: Generating accurate captions with translated text...`);

let accurateCaptionPath = null;

try {
    // ‚úÖ FIX: Load translation from filesystem
    const translationFile = `./uploads/translations/${jobId}_translation.json`;
    let translation = null;
    
    if (fs.existsSync(translationFile)) {
        const translationData = JSON.parse(fs.readFileSync(translationFile, 'utf8'));
        translation = translationData.translation;
        console.log(`[${jobId}] ‚úÖ Translation loaded: ${translation.language}`);
    } else {
        console.warn(`[${jobId}] ‚ö†Ô∏è Translation file not found, checking alternate paths...`);
        
        // Try alternate paths
        const alternatePaths = [
            `./uploads/translation/${jobId}.json`,
            `./uploads/translations/${jobId}.json`
        ];
        
        for (const altPath of alternatePaths) {
            if (fs.existsSync(altPath)) {
                const data = JSON.parse(fs.readFileSync(altPath, 'utf8'));
                translation = data.translation || data;
                break;
            }
        }
    }
    
    if (!translation) {
        throw new Error('Translation data not found - cannot generate captions');
    }
    
    accurateCaptionPath = await generateAccurateCaptions(
        jobId, 
        alignmentData, 
        translation  // ‚úÖ Now correctly passed
    );
    
    if (accurateCaptionPath && fs.existsSync(accurateCaptionPath)) {
        console.log(`[${jobId}] ‚úÖ Captions ready in ${translation.language}: ${accurateCaptionPath}`);
    } else {
        console.log(`[${jobId}] ‚ö†Ô∏è Captions not available - continuing without them`);
    }
} catch (captionError) {
    console.warn(`[${jobId}] ‚ö†Ô∏è Caption generation failed: ${captionError.message}`);
    accurateCaptionPath = null;
}


      // ===== STEP 7: FRAME-PERFECT VIDEO ASSEMBLY WITH FIXED SUBTITLE EMBEDDING =====
      console.log(`[${jobId}] Step 7/8: Frame-perfect video assembly with embedded sync data...`);
      const hasCaptions = accurateCaptionPath && fs.existsSync(accurateCaptionPath);
const assemblyResults = await performFramePerfectVideoAssemblyFixed(
  originalVideoPath,
  neuralCorrectedAudioPath,
  accurateCaptionPath || null, // Pass null if captions not available
  outputVideoPath,
  frameLevelValidation,
  neuralSyncResults,
  lipSyncValidation,
  jobId
);
      console.log(`[${jobId}] ‚úÖ Frame-perfect assembly completed successfully`);

      // ===== STEP 8: COMPREHENSIVE FINAL VALIDATION =====
      console.log(`[${jobId}] Step 8/8: Comprehensive final validation...`);
      const finalValidation = await performComprehensiveFinalValidation(
        outputVideoPath,
        originalVideoPath,
        neuralCorrectedAudioPath,
        lipSyncValidation,
        jobId
      );

      // ===== CLEANUP ADVANCED TEMPORARY FILES =====
      await cleanupAdvancedTemporaryFiles([
        realTimeSyncedAudioPath,
        neuralCorrectedAudioPath
      ], translatedAudioPath, jobId);

      // ===== RETURN COMPREHENSIVE RESULTS =====
      const comprehensiveResults = {
        outputPath: outputVideoPath,
        validation: finalValidation,
        lipSync: {
          reference: lipSyncReference,
          validation: lipSyncValidation,
          quality: lipSyncValidation.overallGrade
        },
        neuralSync: neuralSyncResults,
        phonemeAlignment: phonemeAlignment,
        frameLevelStats: frameLevelValidation,
        processingStats: {
          ...(assemblyResults?.stats || {}),
          totalProcessingTime: Date.now() - (assemblyResults?.stats?.startTime || Date.now()),
          stepsCompleted: 8,
          enhancementsApplied: [
            'frame_level_alignment',
            'real_time_sync',
            'neural_validation',
            'lip_sync_analysis',
            'phoneme_alignment',
            'subtitle_embedding'
          ]
        }
      };

      console.log(`[${jobId}] ‚úÖ All enhancements successfully applied and validated`);
      resolve(comprehensiveResults);

    } catch (error) {
      console.error(`[${jobId}] ‚ùå Enhanced frame-level video assembly failed:`, error.message);
      console.error(`[${jobId}] Error stack:`, error.stack);
      reject(error);
    }
  });
};

// ===== CAPTION GENERATION HELPERS =====

export async function generateAccurateCaptions(jobId, alignmentData, translatedSegments) {
    console.log(`[${jobId}] Generating captions from translated text...`);
    
    try {
        // ‚úÖ FIX: Use translatedSegments (translation data) instead of alignment word timings
        if (!translatedSegments || !translatedSegments.text) {
            console.warn(`[${jobId}] ‚ö†Ô∏è No translation data available`);
            return null;
        }
        
        const targetLanguage = translatedSegments.language || translatedSegments.targetLang || 'en';
        const targetLanguageName = getLanguageName(targetLanguage);
        
        console.log(`[${jobId}] Caption language: ${targetLanguageName} (${targetLanguage})`);
        
        // ‚úÖ Split translation text into sentences
        const sentences = translatedSegments.text
            .split(/[‡•§.!?;|\u0964\u0965\u061F\u3002\u0589\u06D4\u2026]+/)
            .map(s => s.trim())
            .filter(s => s.length > 0);
        
        if (sentences.length === 0) {
            sentences.push(translatedSegments.text.trim());
        }
        
        console.log(`[${jobId}] Split into ${sentences.length} ${targetLanguageName} sentences`);
        
        // ‚úÖ Calculate timing from alignment data
        const totalDuration = alignmentData?.duration || 30;
        const sentenceWordCounts = sentences.map(s => s.split(/\s+/).length);
        const totalWords = sentenceWordCounts.reduce((sum, count) => sum + count, 0);
        
        // ‚úÖ Create timed segments with proportional timing
        let currentTime = 0;
        const segments = sentences.map((sentence, index) => {
            const wordCount = sentenceWordCounts[index];
            const proportion = wordCount / totalWords;
            const duration = totalDuration * proportion;
            
            const segment = {
                start: currentTime,
                end: Math.min(currentTime + duration, totalDuration),
                text: sentence.trim(),
                wordCount: wordCount
            };
            
            currentTime += duration;
            return segment;
        });
        
        console.log(`[${jobId}] Created ${segments.length} timed segments in ${targetLanguageName}`);
        
        // Ensure captions directory exists
        const captionsDir = path.join(process.cwd(), 'uploads', 'captions');
        if (!fs.existsSync(captionsDir)) {
            fs.mkdirSync(captionsDir, { recursive: true });
        }
        
        const accurateCaptionPath = path.join(captionsDir, `${jobId}_captions_accurate.vtt`);
        
        // ‚úÖ Create VTT content with 5 words per caption
        let vttContent = `WEBVTT
Kind: captions
Language: ${targetLanguage}

NOTE
Generated from ${targetLanguageName} translation
${segments.length} segments
Generated: ${new Date().toISOString()}

`;
        
        // ‚úÖ Extract words from segments and group into 5-word captions
        const allWords = [];
        segments.forEach(segment => {
            const words = segment.text.split(/\s+/).filter(w => w.length > 0);
            const wordDuration = (segment.end - segment.start) / words.length;
            
            words.forEach((word, idx) => {
                allWords.push({
                    word: word,
                    start: segment.start + (idx * wordDuration),
                    end: segment.start + ((idx + 1) * wordDuration)
                });
            });
        });
        
        // ‚úÖ Group into 5-word captions
        const WORDS_PER_CAPTION = 5;
        let captionIndex = 1;
        
        for (let i = 0; i < allWords.length; i += WORDS_PER_CAPTION) {
            const wordGroup = allWords.slice(i, i + WORDS_PER_CAPTION);
            if (wordGroup.length === 0) continue;
            
            const startTime = formatTimeVTT(wordGroup[0].start);
            const endTime = formatTimeVTT(wordGroup[wordGroup.length - 1].end);
            const text = wordGroup.map(w => w.word).join(' ');
            
            vttContent += `${captionIndex}\n${startTime} --> ${endTime}\n${text}\n\n`;
            captionIndex++;
        }
        
        fs.writeFileSync(accurateCaptionPath, vttContent, 'utf8');
        
        console.log(`[${jobId}] ‚úÖ Accurate VTT caption file saved to ${accurateCaptionPath}`);
        console.log(`[${jobId}] Generated ${captionIndex - 1} captions in ${targetLanguageName}`);
        
        return accurateCaptionPath;
        
    } catch (error) {
        console.warn(`[${jobId}] ‚ö†Ô∏è Caption generation failed: ${error.message}`);
        return null;
    }
}

// ‚úÖ Helper function for time formatting (ADD THIS)
function formatTimeVTT(seconds) {
    const hours = Math.floor(seconds / 3600);
    const minutes = Math.floor((seconds % 3600) / 60);
    const secs = (seconds % 60).toFixed(3);
    return `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${secs.padStart(6, '0')}`;
}

// ‚úÖ Helper function for language names (ADD THIS)
function getLanguageName(langCode) {
    const names = {
        'hi': 'Hindi', 'gu': 'Gujarati', 'kn': 'Kannada',
        'te': 'Telugu', 'ta': 'Tamil', 'bn': 'Bengali',
        'ml': 'Malayalam', 'mr': 'Marathi', 'ur': 'Urdu',
        'pa': 'Punjabi', 'en': 'English'
    };
    return names[langCode] || langCode;
}


function generateVTTFromWordTimings(wordTimings, segments) {
    let vtt = 'WEBVTT\n\n';
    
    if (!wordTimings || wordTimings.length === 0) {
        return null;
    }
    
    // If segments exist, use them
    if (segments && segments.length > 0) {
        segments.forEach((segment, index) => {
            if (segment.text) {
                const startTime = formatVTTTime(segment.start || 0);
                const endTime = formatVTTTime(segment.end || 0);
                
                vtt += `${index + 1}\n`;
                vtt += `${startTime} --> ${endTime}\n`;
                vtt += `${segment.text}\n\n`;
            }
        });
    } else {
        // Use word timings directly
        wordTimings.forEach((timing, index) => {
            const text = timing.word || timing.text || timing.phoneme || '';
            const start = timing.start || 0;
            const end = timing.end || start + 0.5;
            
            if (text) {
                const startTime = formatVTTTime(start);
                const endTime = formatVTTTime(end);
                
                vtt += `${index + 1}\n`;
                vtt += `${startTime} --> ${endTime}\n`;
                vtt += `${text}\n\n`;
            }
        });
    }
    
    return vtt;
}

function formatVTTTime(seconds) {
    const hours = Math.floor(seconds / 3600);
    const minutes = Math.floor((seconds % 3600) / 60);
    const secs = Math.floor(seconds % 60);
    const ms = Math.floor((seconds % 1) * 1000);
    
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(3, '0')}`;
}



// ===== DISCOVER JOB FILES WITH ADVANCED SEARCH =====
const discoverJobFilesAdvanced = async (jobId) => {
  console.log(`[${jobId}] Performing advanced file discovery with multiple search strategies...`);

  const filePaths = {
    originalVideo: null,
    translatedAudio: null,
    captions: null,
    transcript: null,
    alignmentData: null,
    lipSyncData: null
  };

  // ===== ADVANCED VIDEO DISCOVERY =====
  const videoSearchStrategy = {
    extensions: ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.wmv'],
    searchDirs: [
      './uploads/originals/',
      './uploads/',
      './uploads/processed/',
      './temp/',
      './'
    ],
    priorityPatterns: [
      `${jobId}.mp4`,
      `${jobId}.mov`,
      `${jobId}_original.mp4`,
      `original_${jobId}.mp4`
    ]
  };

  for (const dir of videoSearchStrategy.searchDirs) {
    if (!fs.existsSync(dir)) continue;

    try {
      const files = fs.readdirSync(dir);

      // Priority 1: Exact job ID match
      for (const pattern of videoSearchStrategy.priorityPatterns) {
        if (files.includes(pattern)) {
          filePaths.originalVideo = path.join(dir, pattern);
          console.log(`[${jobId}] Found priority video: ${filePaths.originalVideo}`);
          break;
        }
      }

      if (filePaths.originalVideo) break;

      // Priority 2: Job ID containing files
      const jobContaining = files.find(file =>
        file.includes(jobId) &&
        videoSearchStrategy.extensions.some(ext => file.toLowerCase().endsWith(ext))
      );

      if (jobContaining) {
        filePaths.originalVideo = path.join(dir, jobContaining);
        console.log(`[${jobId}] Found job-containing video: ${filePaths.originalVideo}`);
        break;
      }

      // Priority 3: Most recent video file
      const videoFiles = files.filter(file =>
        videoSearchStrategy.extensions.some(ext => file.toLowerCase().endsWith(ext))
      );

      if (videoFiles.length > 0) {
        const mostRecent = videoFiles
          .map(file => ({
            name: file,
            path: path.join(dir, file),
            mtime: fs.statSync(path.join(dir, file)).mtime,
            size: fs.statSync(path.join(dir, file)).size
          }))
          .filter(f => f.size > 1000000) // At least 1MB
          .sort((a, b) => b.mtime - a.mtime)[0];

        if (mostRecent) {
          filePaths.originalVideo = mostRecent.path;
          console.log(`[${jobId}] Using most recent video: ${mostRecent.name} (${Math.round(mostRecent.size / 1024 / 1024)}MB)`);
          break;
        }
      }

    } catch (dirError) {
      console.warn(`[${jobId}] Failed to search directory ${dir}:`, dirError.message);
    }
  }

  // ===== ADVANCED AUDIO DISCOVERY =====
  const audioSearchPaths = [
    `./uploads/translated_audio/${jobId}_translated.wav`,
    `./uploads/translated_audio/${jobId}_translated.mp3`,
    `./uploads/translated_audio/${jobId}_translated.m4a`,
    `./uploads/translated_audio/${jobId}_neural_synced.wav`,
    `./uploads/translated_audio/${jobId}_realtime_sync.wav`,
    `./uploads/audio/${jobId}_audio.wav`
  ];

  for (const audioPath of audioSearchPaths) {
    if (fs.existsSync(audioPath)) {
      const audioStats = fs.statSync(audioPath);
      if (audioStats.size > 10000) { // At least 10KB
        filePaths.translatedAudio = audioPath;
        console.log(`[${jobId}] Found translated audio: ${audioPath} (${Math.round(audioStats.size / 1024)}KB)`);
        break;
      }
    }
  }

  // ===== CAPTION DISCOVERY =====
  const captionSearchPaths = [
    `./uploads/captions/${jobId}_captions.vtt`,
    `./uploads/captions/${jobId}_captions.srt`,
    `./uploads/captions/${jobId}.vtt`,
    `./uploads/captions/${jobId}.srt`
  ];

  for (const captionPath of captionSearchPaths) {
    if (fs.existsSync(captionPath)) {
      filePaths.captions = captionPath;
      console.log(`[${jobId}] Found captions: ${captionPath}`);
      break;
    }
  }

  // ===== TRANSCRIPT DISCOVERY =====
  const transcriptSearchPaths = [
    `./uploads/transcripts/${jobId}_transcript.txt`,
    `./uploads/transcripts/${jobId}_sr_output.json`,
    `./uploads/transcripts/${jobId}.txt`
  ];

  for (const transcriptPath of transcriptSearchPaths) {
    if (fs.existsSync(transcriptPath)) {
      filePaths.transcript = transcriptPath;
      console.log(`[${jobId}] Found transcript: ${transcriptPath}`);
      break;
    }
  }

  // ===== ALIGNMENT DATA DISCOVERY =====
  const alignmentPaths = [
    `./uploads/alignment/${jobId}/alignment.json`,
    `./uploads/alignment/${jobId}_alignment.json`,
    `./uploads/forced_alignment/${jobId}.json`
  ];

  for (const alignPath of alignmentPaths) {
    if (fs.existsSync(alignPath)) {
      try {
        const alignmentContent = fs.readFileSync(alignPath, 'utf8');
        filePaths.alignmentData = JSON.parse(alignmentContent);
        console.log(`[${jobId}] Found alignment data: ${alignPath}`);
        break;
      } catch (parseError) {
        console.warn(`[${jobId}] Failed to parse alignment data from ${alignPath}:`, parseError.message);
      }
    }
  }

  // ===== LIP SYNC DATA DISCOVERY =====
  const lipSyncPaths = [
    `./uploads/lip_analysis/${jobId}/lip_movement_analysis.json`,
    `./uploads/lip_sync/${jobId}.json`,
    `./uploads/lip_analysis/${jobId}_timeline.json`
  ];

  for (const lipPath of lipSyncPaths) {
    if (fs.existsSync(lipPath)) {
      try {
        const lipSyncContent = fs.readFileSync(lipPath, 'utf8');
        filePaths.lipSyncData = JSON.parse(lipSyncContent);
        console.log(`[${jobId}] Found lip sync data: ${lipPath}`);
        break;
      } catch (parseError) {
        console.warn(`[${jobId}] Failed to parse lip sync data from ${lipPath}:`, parseError.message);
      }
    }
  }

  return filePaths;
};

// ===== FRAME-LEVEL DURATION VALIDATION =====
const performFrameLevelDurationValidation = async (videoPath, audioPath, lipSyncReference, phonemeAlignment, jobId) => {
  console.log(`[${jobId}] Performing frame-level duration validation with microsecond precision...`);

  try {
    // Get ultra-precise video metadata
    const videoMetadata = await getUltraPreciseVideoMetadata(videoPath);
    const audioMetadata = await getUltraPreciseAudioMetadata(audioPath);

    const videoDuration = videoMetadata.duration;
    const audioDuration = audioMetadata.duration;
    const fps = videoMetadata.fps;
    const frameDuration = 1 / fps;

    // Calculate frame-level accuracy
    const durationDifference = Math.abs(videoDuration - audioDuration);
    const frameAccuracy = durationDifference / frameDuration;

    // Advanced sync quality determination
    let syncQuality = 'excellent';
    let requiresAdjustment = false;
    let adjustmentStrategy = 'none';

    if (frameAccuracy > 5) { // More than 5 frames off
      syncQuality = 'poor';
      requiresAdjustment = true;
      adjustmentStrategy = 'major_correction';
    } else if (frameAccuracy > 2) { // More than 2 frames off
      syncQuality = 'fair';
      requiresAdjustment = true;
      adjustmentStrategy = 'moderate_correction';
    } else if (frameAccuracy > 0.5) { // More than half frame off
      syncQuality = 'good';
      requiresAdjustment = durationDifference > 0.05; // Only if > 50ms
      adjustmentStrategy = 'fine_tuning';
    }

    // Factor in lip sync and phoneme data quality
    if (lipSyncReference && lipSyncReference.confidence_level === 'high') {
      if (syncQuality === 'fair') syncQuality = 'good';
      adjustmentStrategy = 'lip_sync_guided';
    }

    if (phonemeAlignment && phonemeAlignment.lip_sync_enabled) {
      if (syncQuality === 'good') syncQuality = 'very_good';
      adjustmentStrategy = 'phoneme_guided';
    }

    // Calculate precision metrics
    const millisecondAccuracy = frameAccuracy * frameDuration * 1000;
    const frameSync = {
      totalFrames: Math.floor(videoDuration * fps),
      syncedFrames: Math.floor((videoDuration - durationDifference) * fps),
      unsyncedFrames: Math.floor(durationDifference * fps)
    };

    const validation = {
      videoDuration,
      audioDuration,
      durationDifference,
      frameAccuracy,
      frameDuration,
      fps,
      syncQuality,
      requiresAdjustment,
      adjustmentStrategy,
      millisecondAccuracy,
      frameSync,
      videoMetadata,
      audioMetadata,
      precision: {
        frameLevel: frameAccuracy < 1,
        subFrameLevel: frameAccuracy < 0.5,
        millisecondLevel: millisecondAccuracy < 50
      },
      confidence: lipSyncReference ? lipSyncReference.confidence_level : 'medium'
    };

    console.log(`[${jobId}] Frame-level validation completed:`);
    console.log(`[${jobId}]   Frame accuracy: ${frameAccuracy.toFixed(4)} frames (${millisecondAccuracy.toFixed(2)}ms)`);
    console.log(`[${jobId}]   Sync quality: ${syncQuality}`);
    console.log(`[${jobId}]   Strategy: ${adjustmentStrategy}`);
    console.log(`[${jobId}]   Precision levels: Frame(${validation.precision.frameLevel}) SubFrame(${validation.precision.subFrameLevel}) MS(${validation.precision.millisecondLevel})`);

    return validation;

  } catch (error) {
    console.error(`[${jobId}] Frame-level validation failed:`, error.message);
    throw error;
  }
};

// ===== REAL-TIME SYNC ADJUSTMENT =====
const performRealTimeSyncAdjustment = async (audioPath, videoPath, frameLevelValidation, lipSyncReference, phonemeAlignment, jobId) => {
  console.log(`[${jobId}] Performing real-time sync adjustment with frame-level precision...`);

  try {
    const adjustedAudioPath = audioPath.replace(/\.(wav|mp3|m4a)$/, '_realtime_sync.$1');
    const strategy = frameLevelValidation.adjustmentStrategy;
    const targetDuration = frameLevelValidation.videoDuration;
    const currentDuration = frameLevelValidation.audioDuration;

    console.log(`[${jobId}] Real-time adjustment strategy: ${strategy}`);
    console.log(`[${jobId}] Target precision: ${frameLevelValidation.frameAccuracy.toFixed(4)} frames`);

    // Choose adjustment method based on available data and strategy
    switch (strategy) {
      case 'phoneme_guided':
        if (phonemeAlignment) {
          await applyPhonemeGuidedAdjustment(
            audioPath,
            adjustedAudioPath,
            targetDuration,
            phonemeAlignment,
            jobId
          );
          break;
        }
      // Fall through to lip sync guided

      case 'lip_sync_guided':
        if (lipSyncReference) {
          await applyLipSyncGuidedAdjustment(
            audioPath,
            adjustedAudioPath,
            targetDuration,
            lipSyncReference,
            jobId
          );
          break;
        }
      // Fall through to frame perfect

      case 'major_correction':
      case 'moderate_correction':
      case 'fine_tuning':
      default:
        await applyFramePerfectAdjustment(
          audioPath,
          adjustedAudioPath,
          targetDuration,
          currentDuration,
          frameLevelValidation,
          jobId
        );
        break;
    }

    // Validate the real-time adjustment
    const adjustedDuration = await getUltraPreciseAudioDuration(adjustedAudioPath);
    const finalAccuracy = Math.abs(adjustedDuration - targetDuration);
    const frameImprovement = Math.abs(frameLevelValidation.frameAccuracy - (finalAccuracy / frameLevelValidation.frameDuration));

    console.log(`[${jobId}] Real-time adjustment results:`);
    console.log(`[${jobId}]   Final duration: ${adjustedDuration.toFixed(4)}s`);
    console.log(`[${jobId}]   Final accuracy: ${(finalAccuracy * 1000).toFixed(2)}ms`);
    console.log(`[${jobId}]   Frame improvement: ${frameImprovement.toFixed(4)} frames`);
    console.log(`[${jobId}]   Success: ${finalAccuracy < 0.1 ? '‚úÖ EXCELLENT' : finalAccuracy < 0.5 ? '‚úÖ GOOD' : '‚ö†Ô∏è PARTIAL'}`);

    return adjustedAudioPath;

  } catch (error) {
    console.error(`[${jobId}] Real-time sync adjustment failed:`, error.message);
    console.warn(`[${jobId}] Using original audio without real-time adjustment`);
    return audioPath;
  }
};

// ===== APPLY PHONEME GUIDED ADJUSTMENT =====
const applyPhonemeGuidedAdjustment = async (inputPath, outputPath, targetDuration, phonemeAlignment, jobId) => {
  console.log(`[${jobId}] Applying phoneme-guided real-time adjustment...`);

  if (!phonemeAlignment.phoneme_timings || phonemeAlignment.phoneme_timings.length === 0) {
    throw new Error('No phoneme timings available for guided adjustment');
  }

  // Create complex filter based on phoneme timings
  const phonemeTimings = phonemeAlignment.phoneme_timings;
  const totalPhonemes = phonemeTimings.length;

  // Calculate tempo adjustments per phoneme segment
  const filterParts = [];
  let currentTime = 0;

  for (let i = 0; i < totalPhonemes; i++) {
    const phoneme = phonemeTimings[i];
    const segmentDuration = phoneme.duration;
    const targetSegmentDuration = (targetDuration / totalPhonemes);

    const tempoRatio = segmentDuration / targetSegmentDuration;
    const clampedTempo = Math.max(0.5, Math.min(2.0, tempoRatio));

    if (i === 0) {
      filterParts.push(`[0:a]atempo=${clampedTempo.toFixed(3)}[a${i}]`);
    } else {
      filterParts.push(`[a${i - 1}]atempo=${clampedTempo.toFixed(3)}[a${i}]`);
    }

    currentTime += targetSegmentDuration;
  }

  const complexFilter = filterParts.join(';');
  const command = `ffmpeg -i "${inputPath}" -filter_complex "${complexFilter}" -af "afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -t ${targetDuration} -y "${outputPath}"`;

  console.log(`[${jobId}] Phoneme-guided adjustment with ${totalPhonemes} segments`);

  return execAsync(command);
};

// ===== APPLY LIP SYNC GUIDED ADJUSTMENT =====
const applyLipSyncGuidedAdjustment = async (inputPath, outputPath, targetDuration, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Applying lip sync-guided real-time adjustment...`);

  if (!lipSyncReference.sync_points || lipSyncReference.sync_points.length === 0) {
    throw new Error('No lip sync points available for guided adjustment');
  }

  const syncPoints = lipSyncReference.sync_points;
  const segmentCount = Math.min(syncPoints.length, 10); // Limit complexity

  // Create variable tempo adjustments based on lip movement intensity
  const filterParts = [];
  const segmentDuration = targetDuration / segmentCount;

  for (let i = 0; i < segmentCount; i++) {
    const relevantPoints = syncPoints.filter(sp =>
      sp.timestamp >= (i * segmentDuration) &&
      sp.timestamp < ((i + 1) * segmentDuration)
    );

    let intensityFactor = 0.7; // Default
    if (relevantPoints.length > 0) {
      intensityFactor = relevantPoints.reduce((sum, point) => sum + point.intensity, 0) / relevantPoints.length;
    }

    // Convert intensity to tempo (higher intensity = slightly faster speech)
    const tempoAdjustment = 0.85 + (intensityFactor * 0.3); // Range: 0.85 - 1.15

    if (i === 0) {
      filterParts.push(`[0:a]atempo=${tempoAdjustment.toFixed(3)}[a${i}]`);
    } else {
      filterParts.push(`[a${i - 1}]atempo=${tempoAdjustment.toFixed(3)}[a${i}]`);
    }
  }

  const complexFilter = filterParts.join(';');
  const command = `ffmpeg -i "${inputPath}" -filter_complex "${complexFilter}" -af "afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -t ${targetDuration} -y "${outputPath}"`;

  console.log(`[${jobId}] Lip sync-guided adjustment with ${segmentCount} intensity-based segments`);

  return execAsync(command);
};

// ===== APPLY FRAME PERFECT ADJUSTMENT =====
const applyFramePerfectAdjustment = async (inputPath, outputPath, targetDuration, currentDuration, frameLevelValidation, jobId) => {
  console.log(`[${jobId}] Applying frame-perfect adjustment...`);

  const adjustmentRatio = currentDuration / targetDuration;
  const frameAccuracy = frameLevelValidation.frameAccuracy;
  const fps = frameLevelValidation.fps;

  // Choose adjustment method based on frame accuracy
  let command;

  if (frameAccuracy < 0.1) {
    // Sub-frame accuracy needed - use precise padding/trimming
    if (currentDuration > targetDuration) {
      const trimAmount = currentDuration - targetDuration;
      command = `ffmpeg -i "${inputPath}" -ss 0 -t ${targetDuration} -af "afade=out:st=${targetDuration - 0.001}:d=0.001" -y "${outputPath}"`;
    } else {
      const padAmount = targetDuration - currentDuration;
      command = `ffmpeg -i "${inputPath}" -af "apad=pad_dur=${padAmount},afade=in:st=0:d=0.001" -y "${outputPath}"`;
    }
  } else if (frameAccuracy < 1) {
    // Frame-level accuracy - use micro tempo adjustment
    const microTempo = Math.max(0.99, Math.min(1.01, adjustmentRatio));
    command = `ffmpeg -i "${inputPath}" -af "atempo=${microTempo.toFixed(6)},afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -y "${outputPath}"`;
  } else {
    // Standard tempo adjustment with quality preservation
    const clampedRatio = Math.max(0.5, Math.min(2.0, adjustmentRatio));
    command = `ffmpeg -i "${inputPath}" -af "atempo=${clampedRatio.toFixed(4)},afade=in:st=0:d=0.01,afade=out:st=${targetDuration - 0.01}:d=0.01" -y "${outputPath}"`;
  }

  console.log(`[${jobId}] Frame-perfect adjustment: ${frameAccuracy.toFixed(4)} frame accuracy, ratio: ${adjustmentRatio.toFixed(6)}`);

  return execAsync(command);
};

// ===== ADVANCED NEURAL SYNC VALIDATION =====
const performAdvancedNeuralSyncValidation = async (videoPath, audioPath, lipSyncReference, phonemeAlignment, jobId) => {
  console.log(`[${jobId}] Performing advanced neural sync validation...`);

  try {
    // Use enhanced neural sync detection with all available data
    const neuralSyncResults = await detectAudioVideoSync(videoPath, audioPath, jobId, lipSyncReference);

    // Additional phoneme-based validation if available
    let phonemeValidation = null;
    if (phonemeAlignment && phonemeAlignment.phoneme_timings) {
      phonemeValidation = await validatePhonemeSync(audioPath, phonemeAlignment, jobId);
    }

    // Additional lip sync cross-validation
    let lipSyncValidation = null;
    if (lipSyncReference && lipSyncReference.sync_points) {
      lipSyncValidation = await validateAgainstLipSyncPoints(audioPath, lipSyncReference, jobId);
    }

    // Combine all validation results
    const combinedResults = {
      neural: neuralSyncResults,
      phoneme: phonemeValidation,
      lipSync: lipSyncValidation,
      overallQuality: determineOverallSyncQuality(neuralSyncResults, phonemeValidation, lipSyncValidation),
      requiresCorrection: false,
      recommendedCorrection: null,
      confidence: 0
    };

    // Calculate combined confidence
    let totalConfidence = neuralSyncResults.confidence;
    let confidenceCount = 1;

    if (phonemeValidation) {
      totalConfidence += phonemeValidation.confidence;
      confidenceCount++;
    }

    if (lipSyncValidation) {
      totalConfidence += lipSyncValidation.confidence;
      confidenceCount++;
    }

    combinedResults.confidence = totalConfidence / confidenceCount;

    // Determine if correction is needed
    const needsCorrection = (
      combinedResults.overallQuality === 'poor' ||
      (combinedResults.confidence < 0.6 && Math.abs(neuralSyncResults.sync_offset) > 0.05) ||
      (lipSyncValidation && lipSyncValidation.accuracy < 0.7)
    );

    if (needsCorrection) {
      combinedResults.requiresCorrection = true;

      // Choose best correction method
      let correctionMethod = 'neural_only';
      if (phonemeValidation && phonemeValidation.confidence > 0.8) {
        correctionMethod = 'phoneme_guided';
      } else if (lipSyncValidation && lipSyncValidation.confidence > 0.7) {
        correctionMethod = 'lip_sync_guided';
      }

      combinedResults.recommendedCorrection = {
        method: correctionMethod,
        offset: neuralSyncResults.sync_offset,
        confidence: combinedResults.confidence,
        priority: combinedResults.overallQuality === 'poor' ? 'high' : 'medium'
      };
    }

    console.log(`[${jobId}] Advanced neural sync validation completed:`);
    console.log(`[${jobId}]   Overall quality: ${combinedResults.overallQuality}`);
    console.log(`[${jobId}]   Combined confidence: ${(combinedResults.confidence * 100).toFixed(1)}%`);
    console.log(`[${jobId}]   Neural offset: ${neuralSyncResults.sync_offset.toFixed(3)}s`);
    console.log(`[${jobId}]   Correction needed: ${combinedResults.requiresCorrection ? 'YES' : 'NO'}`);
    console.log(`[${jobId}]   Validation methods: Neural(‚úÖ) Phoneme(${phonemeValidation ? '‚úÖ' : '‚ùå'}) LipSync(${lipSyncValidation ? '‚úÖ' : '‚ùå'})`);

    return combinedResults;

  } catch (error) {
    console.error(`[${jobId}] Advanced neural sync validation failed:`, error.message);

    // Return fallback results
    return {
      neural: { sync_offset: 0, confidence: 0.3, sync_quality: 'unknown' },
      phoneme: null,
      lipSync: null,
      overallQuality: 'unknown',
      requiresCorrection: false,
      confidence: 0.3,
      error: error.message
    };
  }
};

// ===== APPLY NEURAL SYNC CORRECTION =====
const applyNeuralSyncCorrection = async (audioPath, videoPath, neuralSyncResults, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Applying neural sync correction...`);

  const correctedAudioPath = audioPath.replace(/\.(wav|mp3|m4a)$/, '_neural_corrected.$1');
  const correction = neuralSyncResults.recommendedCorrection;
  const offset = correction.offset;

  try {
    switch (correction.method) {
      case 'phoneme_guided':
        await correctAudioSync(audioPath, videoPath, offset, jobId);
        // Additional phoneme-specific corrections would go here
        break;

      case 'lip_sync_guided':
        await correctAudioSync(audioPath, videoPath, offset, jobId);
        // Additional lip sync-specific corrections would go here
        break;

      case 'neural_only':
      default:
        await correctAudioSync(audioPath, videoPath, offset, jobId);
        break;
    }

    // Copy the corrected file to our naming convention
    const correctedTempPath = audioPath.replace(/\.(wav|mp3|m4a)$/, '_synced.$1');
    if (fs.existsSync(correctedTempPath)) {
      fs.copyFileSync(correctedTempPath, correctedAudioPath);

      // Cleanup temp file
      try {
        fs.unlinkSync(correctedTempPath);
      } catch (cleanupError) {
        console.warn(`[${jobId}] Failed to cleanup temp file:`, cleanupError.message);
      }
    } else {
      // If correction didn't create expected file, copy original
      fs.copyFileSync(audioPath, correctedAudioPath);
    }

    console.log(`[${jobId}] Neural sync correction applied with method: ${correction.method}`);
    return correctedAudioPath;

  } catch (error) {
    console.error(`[${jobId}] Neural sync correction failed:`, error.message);

    // Return original audio if correction fails
    console.warn(`[${jobId}] Using original audio due to correction failure`);
    return audioPath;
  }
};

// ===== VALIDATE FINAL LIP SYNC =====
const validateFinalLipSync = async (videoPath, audioPath, lipSyncReference, phonemeAlignment, jobId) => {
  console.log(`[${jobId}] Performing final lip sync validation...`);

  try {
    // If we have lip sync reference, validate against it
    if (lipSyncReference && lipSyncReference.sync_points) {
      const lipSyncAccuracy = await calculateLipSyncAccuracy(audioPath, lipSyncReference, jobId);

      return {
        accuracy: lipSyncAccuracy.accuracy,
        lipMatchScore: lipSyncAccuracy.matchScore,
        overallGrade: lipSyncAccuracy.grade,
        method: 'lip_sync_reference',
        confidence: lipSyncAccuracy.confidence,
        details: lipSyncAccuracy.details
      };
    }

    // Fallback: basic duration validation
    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const videoDuration = await getUltraPreciseVideoDuration(videoPath);
    const durationAccuracy = 1 - Math.abs(audioDuration - videoDuration) / videoDuration;

    return {
      accuracy: Math.max(0, durationAccuracy),
      lipMatchScore: 0.5, // Unknown without analysis
      overallGrade: durationAccuracy > 0.95 ? 'excellent' : durationAccuracy > 0.9 ? 'good' : 'fair',
      method: 'duration_fallback',
      confidence: 0.5,
      details: {
        audioDuration,
        videoDuration,
        durationDifference: Math.abs(audioDuration - videoDuration)
      }
    };

  } catch (error) {
    console.error(`[${jobId}] Final lip sync validation failed:`, error.message);

    return {
      accuracy: 0.5,
      lipMatchScore: 0.5,
      overallGrade: 'unknown',
      method: 'error_fallback',
      confidence: 0.3,
      error: error.message
    };
  }
};

// ‚úÖ CRITICAL FIX: FRAME-PERFECT VIDEO ASSEMBLY WITH PROPER SUBTITLE EMBEDDING
// ===== CRITICAL FIX: FRAME-PERFECT VIDEO ASSEMBLY WITH PROPER SUBTITLE EMBEDDING =====
const performFramePerfectVideoAssemblyFixed = async (
  videoPath,
  audioPath,
  captionPath,
  outputPath,
  frameLevelValidation,
  neuralSyncResults,
  lipSyncValidation,
  jobId
) => {
  console.log(`[${jobId}] Performing frame-perfect video assembly using robust 'spawn' method...`);

  // ‚úÖ Initialize stats object
  const stats = {
    startTime: Date.now(),
    inputSizes: {},
    processingSteps: [],
    finalStats: null
  };

  try {
    // ‚úÖ Record input file sizes
    stats.inputSizes.video = fs.existsSync(videoPath) ? fs.statSync(videoPath).size : 0;
    stats.inputSizes.audio = fs.existsSync(audioPath) ? fs.statSync(audioPath).size : 0;
    if (fs.existsSync(captionPath)) {
      stats.inputSizes.captions = fs.statSync(captionPath).size;
    }

    // --- 1. SETUP AND VALIDATION ---
    const hasCaptions = fs.existsSync(captionPath);
    const targetDuration = frameLevelValidation.videoDuration;
    const fps = frameLevelValidation.fps;

    if (!fs.existsSync(videoPath)) throw new Error(`Video input not found: ${videoPath}`);
    if (!fs.existsSync(audioPath)) throw new Error(`Audio input not found: ${audioPath}`);

    const videoPathFixed = path.resolve(videoPath);
    const audioPathFixed = path.resolve(audioPath);
    const outputPathFixed = path.resolve(outputPath);

    console.log(`[${jobId}]   Assembly configuration: Duration=${targetDuration.toFixed(4)}s, FPS=${fps}, Captions=${hasCaptions}`);

    return new Promise((resolve, reject) => {
      // --- 2. BUILD FFMPEG ARGUMENTS ARRAY ---
      const args = [
        '-i', videoPathFixed,
        '-i', audioPathFixed,
        '-map', '0:v',
        '-map', '1:a'
      ];

      // --- 3. BUILD FILTER CHAINS ---
      const videoFilters = ['scale=-2:720', `fps=${fps}`];
      const audioFilters = [
        'aresample=44100',
        'afade=in:st=0:d=0.005',
        `afade=out:st=${targetDuration - 0.005}:d=0.005`
      ];

      if (hasCaptions) {
    const absoluteCaptionPath = path.resolve(captionPath);
    // ‚úÖ FIX: Proper Windows path escaping for FFmpeg
    const escapedCaptionPath = absoluteCaptionPath
        .replace(/\\/g, '/')      // Convert backslashes to forward slashes
        .replace(/:/g, '\\\\:')   // Escape colons for filter syntax (double escape)
        .replace(/'/g, "\\'");    // Escape single quotes
    
    const subtitleFilter = `subtitles='${escapedCaptionPath}':force_style='FontSize=16,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,Outline=2'`;
    videoFilters.push(subtitleFilter);
    console.log(`[${jobId}] ‚úÖ Subtitle filter prepared with path: ${escapedCaptionPath.substring(0, 50)}...`);
}

      if (neuralSyncResults?.neural && Math.abs(neuralSyncResults.neural.sync_offset) > 0.01) {
        const offset = neuralSyncResults.neural.sync_offset;
        console.log(`[${jobId}] Applying neural sync offset: ${offset}s`);
        const delayFilter = offset > 0 ? `adelay=${offset * 1000}:all=1` : `atrim=${Math.abs(offset)}`;
        audioFilters.unshift(delayFilter);
      }

      if (videoFilters.length > 0) args.push('-vf', videoFilters.join(','));
      if (audioFilters.length > 0) args.push('-af', audioFilters.join(','));

      // --- 4. ADD ENCODING OPTIONS ---
      args.push(
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-b:v', '2000k',
        '-b:a', '192k',
        '-preset', 'medium',
        '-crf', '23',
        '-avoid_negative_ts', 'make_zero',
        '-fflags', '+genpts',
        '-t', targetDuration.toString(),
        '-shortest',
        '-y',
        outputPathFixed
      );

      console.log(`[${jobId}] Spawning FFmpeg process...`);
      const ffmpegProcess = spawn(ffmpegStatic, args);

      let stderr = '';

      ffmpegProcess.stderr.on('data', (data) => {
        stderr += data.toString();
      });

      ffmpegProcess.on('close', (code) => {
        if (code === 0) {
          console.log(`[${jobId}] ‚úÖ FFmpeg process completed successfully.`);
          if (!fs.existsSync(outputPath) || fs.statSync(outputPath).size < 10000) {
            return reject(new Error('Assembly finished, but the output file is missing or too small.'));
          }

          // ‚úÖ Calculate final stats and resolve with stats
          const outputStats = fs.statSync(outputPath);
          const processingTime = Date.now() - stats.startTime;

          stats.finalStats = {
            outputSize: outputStats.size,
            processingTime,
            compressionRatio: stats.inputSizes.video > 0 ? outputStats.size / stats.inputSizes.video : 0,
            subtitlesEmbedded: hasCaptions
          };

          resolve({ outputPath, stats });
        } else {
          console.error(`[${jobId}] ‚ùå FFmpeg process exited with code ${code}.`);
          console.error(`[${jobId}] FFmpeg stderr:`, stderr.substring(0, 2000));

          let specificError = `FFmpeg failed with exit code ${code}.`;
          if (stderr.includes('Unable to parse option value')) {
            specificError = 'Subtitle path parsing error inside FFmpeg. Check filter syntax.';
          } else if (stderr.includes('No such file or directory')) {
            specificError = 'An input file was not found by FFmpeg. Check paths.';
          }

          reject(new Error(specificError));
        }
      });

      ffmpegProcess.on('error', (err) => {
        console.error(`[${jobId}] ‚ùå Failed to start FFmpeg process:`, err);
        reject(new Error('Failed to start the FFmpeg subprocess.'));
      });
    });
  } catch (error) {
    console.error(`[${jobId}] ‚ùå A setup error occurred in video assembly:`, error.message);
    throw error;
  }
};




// ===== COMPREHENSIVE FINAL VALIDATION =====
const performComprehensiveFinalValidation = async (outputPath, originalVideoPath, audioPath, lipSyncValidation, jobId) => {
  console.log(`[${jobId}] Performing comprehensive final validation...`);

  try {
    const outputStats = fs.statSync(outputPath);
    const outputMetadata = await getUltraPreciseVideoMetadata(outputPath);
    const originalMetadata = await getUltraPreciseVideoMetadata(originalVideoPath);

    // Duration accuracy validation
    const durationAccuracy = Math.abs(outputMetadata.duration - originalMetadata.duration);
    const frameAccuracy = durationAccuracy / (1 / outputMetadata.fps);

    // Quality assessments
    let syncQuality = 'excellent';
    if (frameAccuracy > 2) syncQuality = 'good';
    if (frameAccuracy > 5) syncQuality = 'fair';
    if (frameAccuracy > 10) syncQuality = 'poor';

    let frameAlignment = 'perfect';
    if (frameAccuracy > 0.5) frameAlignment = 'good';
    if (frameAccuracy > 1) frameAlignment = 'acceptable';
    if (frameAccuracy > 3) frameAlignment = 'poor';

    const audioQuality = lipSyncValidation.overallGrade;
    const lipSyncQuality = lipSyncValidation.accuracy > 0.9 ? 'excellent' :
      lipSyncValidation.accuracy > 0.8 ? 'good' :
        lipSyncValidation.accuracy > 0.7 ? 'fair' : 'poor';

    // Overall quality determination
    const qualityScores = {
      sync: syncQuality === 'excellent' ? 4 : syncQuality === 'good' ? 3 : syncQuality === 'fair' ? 2 : 1,
      frame: frameAlignment === 'perfect' ? 4 : frameAlignment === 'good' ? 3 : frameAlignment === 'acceptable' ? 2 : 1,
      audio: audioQuality === 'excellent' ? 4 : audioQuality === 'good' ? 3 : audioQuality === 'fair' ? 2 : 1,
      lipSync: lipSyncQuality === 'excellent' ? 4 : lipSyncQuality === 'good' ? 3 : lipSyncQuality === 'fair' ? 2 : 1
    };

    const averageScore = (qualityScores.sync + qualityScores.frame + qualityScores.audio + qualityScores.lipSync) / 4;
    const overallQuality = averageScore >= 3.5 ? 'excellent' :
      averageScore >= 2.5 ? 'good' :
        averageScore >= 1.5 ? 'fair' : 'poor';

    const validation = {
      fileSize: outputStats.size,
      durationAccuracy,
      frameAccuracy,
      syncQuality,
      frameAlignment,
      audioQuality,
      lipSyncQuality,
      overallQuality,
      qualityScores,
      averageScore,
      metadata: {
        duration: outputMetadata.duration,
        fps: outputMetadata.fps,
        resolution: `${outputMetadata.width}x${outputMetadata.height}`,
        bitrate: outputMetadata.bitrate || 'unknown'
      },
      validation_timestamp: new Date().toISOString()
    };

    console.log(`[${jobId}] Comprehensive validation completed:`);
    console.log(`[${jobId}]   Duration accuracy: ${(durationAccuracy * 1000).toFixed(2)}ms`);
    console.log(`[${jobId}]   Frame accuracy: ${frameAccuracy.toFixed(4)} frames`);
    console.log(`[${jobId}]   Quality scores: Sync(${qualityScores.sync}) Frame(${qualityScores.frame}) Audio(${qualityScores.audio}) LipSync(${qualityScores.lipSync})`);
    console.log(`[${jobId}]   Overall quality: ${overallQuality} (${averageScore.toFixed(2)}/4.0)`);

    return validation;

  } catch (error) {
    console.error(`[${jobId}] Comprehensive final validation failed:`, error.message);

    // Return minimal validation data
    return {
      fileSize: fs.existsSync(outputPath) ? fs.statSync(outputPath).size : 0,
      durationAccuracy: 999,
      frameAccuracy: 999,
      syncQuality: 'unknown',
      frameAlignment: 'unknown',
      audioQuality: 'unknown',
      lipSyncQuality: 'unknown',
      overallQuality: 'unknown',
      error: error.message,
      validation_timestamp: new Date().toISOString()
    };
  }
};

// ===== HELPER FUNCTIONS =====

// ===== GET ULTRA-PRECISE VIDEO METADATA =====
const getUltraPreciseVideoMetadata = async (videoPath) => {
  return new Promise((resolve, reject) => {
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');
    const command = `ffprobe -v quiet -print_format json -show_streams -show_format "${videoPathFixed}"`;

    exec(command, { timeout: 20000 }, (error, stdout, stderr) => {
      if (error) {
        reject(new Error(`Ultra-precise video metadata extraction failed: ${error.message}`));
        return;
      }

      try {
        const data = JSON.parse(stdout);
        const videoStream = data.streams.find(s => s.codec_type === 'video');

        if (!videoStream) {
          reject(new Error('No video stream found in ultra-precise metadata'));
          return;
        }

        // Parse frame rate with high precision
        let fps = 30; // Default
        if (videoStream.r_frame_rate) {
          const [num, den] = videoStream.r_frame_rate.split('/');
          fps = parseFloat(num) / parseFloat(den);
        }

        const duration = parseFloat(data.format.duration) || 0;
        const bitrate = parseInt(data.format.bit_rate) || 0;

        resolve({
          duration: Math.round(duration * 10000) / 10000, // 4 decimal precision
          fps: Math.round(fps * 1000) / 1000, // 3 decimal precision
          width: videoStream.width || 0,
          height: videoStream.height || 0,
          bitrate: bitrate,
          codec: videoStream.codec_name || 'unknown',
          frameCount: Math.floor(duration * fps)
        });

      } catch (parseError) {
        reject(new Error(`Failed to parse ultra-precise video metadata: ${parseError.message}`));
      }
    });
  });
};

// ===== GET ULTRA-PRECISE AUDIO METADATA =====
const getUltraPreciseAudioMetadata = async (audioPath) => {
  return new Promise((resolve, reject) => {
    const audioPathFixed = path.resolve(audioPath).replace(/\\/g, '/');
    const command = `ffprobe -v quiet -print_format json -show_streams -show_format "${audioPathFixed}"`;

    exec(command, { timeout: 15000 }, (error, stdout, stderr) => {
      if (error) {
        reject(new Error(`Ultra-precise audio metadata extraction failed: ${error.message}`));
        return;
      }

      try {
        const data = JSON.parse(stdout);
        const audioStream = data.streams.find(s => s.codec_type === 'audio');

        if (!audioStream) {
          reject(new Error('No audio stream found in ultra-precise metadata'));
          return;
        }

        const duration = parseFloat(data.format.duration) || 0;
        const bitrate = parseInt(data.format.bit_rate) || parseInt(audioStream.bit_rate) || 0;
        const sampleRate = parseInt(audioStream.sample_rate) || 44100;

        resolve({
          duration: Math.round(duration * 10000) / 10000, // 4 decimal precision
          bitrate: bitrate,
          sampleRate: sampleRate,
          channels: audioStream.channels || 2,
          codec: audioStream.codec_name || 'unknown',
          sampleCount: Math.floor(duration * sampleRate)
        });

      } catch (parseError) {
        reject(new Error(`Failed to parse ultra-precise audio metadata: ${parseError.message}`));
      }
    });
  });
};

// ===== GET ULTRA-PRECISE AUDIO DURATION =====
const getUltraPreciseAudioDuration = async (audioPath) => {
  const metadata = await getUltraPreciseAudioMetadata(audioPath);
  return metadata.duration;
};

// ===== GET ULTRA-PRECISE VIDEO DURATION =====
const getUltraPreciseVideoDuration = async (videoPath) => {
  const metadata = await getUltraPreciseVideoMetadata(videoPath);
  return metadata.duration;
};

// ===== CREATE FALLBACK LIP SYNC REFERENCE =====
const createFallbackLipSyncReference = async (videoPath, jobId) => {
  console.log(`[${jobId}] Creating fallback lip sync reference...`);

  try {
    const videoDuration = await getUltraPreciseVideoDuration(videoPath);
    const segmentDuration = 2.0; // 2-second segments
    const numSegments = Math.ceil(videoDuration / segmentDuration);

    const fallbackSyncPoints = [];

    for (let i = 0; i < numSegments; i++) {
      const timestamp = i * segmentDuration;
      const intensity = 0.5 + Math.random() * 0.3; // Random intensity 0.5-0.8

      fallbackSyncPoints.push({
        timestamp: Math.min(timestamp, videoDuration),
        type: 'speech_segment',
        intensity: intensity,
        confidence: 0.3 // Low confidence for fallback
      });
    }

    return {
      sync_points: fallbackSyncPoints,
      total_points: fallbackSyncPoints.length,
      confidence_level: 'low',
      method: 'fallback_estimate',
      total_duration: videoDuration
    };

  } catch (error) {
    console.error(`[${jobId}] Fallback lip sync reference creation failed:`, error.message);

    // Minimal fallback
    return {
      sync_points: [],
      total_points: 0,
      confidence_level: 'none',
      method: 'minimal_fallback',
      total_duration: 30 // Default assumption
    };
  }
};

// ===== DISCOVER TRANSCRIPT =====
const discoverTranscript = async (jobId) => {
  const transcriptPaths = [
    `./uploads/transcripts/${jobId}_transcript.txt`,
    `./uploads/transcripts/${jobId}_sr_output.json`,
    `./uploads/transcripts/${jobId}.txt`,
    `./uploads/transcription/${jobId}.txt`
  ];

  for (const transcriptPath of transcriptPaths) {
    if (fs.existsSync(transcriptPath)) {
      console.log(`[${jobId}] Found transcript: ${transcriptPath}`);
      return transcriptPath;
    }
  }

  console.warn(`[${jobId}] No transcript file found`);
  return null;
};

// ===== DETERMINE OVERALL SYNC QUALITY =====
const determineOverallSyncQuality = (neuralResults, phonemeValidation, lipSyncValidation) => {
  const qualityScores = [];

  // Neural quality score
  if (neuralResults.sync_quality === 'excellent') qualityScores.push(4);
  else if (neuralResults.sync_quality === 'good') qualityScores.push(3);
  else if (neuralResults.sync_quality === 'fair') qualityScores.push(2);
  else qualityScores.push(1);

  // Phoneme quality score
  if (phonemeValidation) {
    if (phonemeValidation.confidence > 0.8) qualityScores.push(4);
    else if (phonemeValidation.confidence > 0.6) qualityScores.push(3);
    else if (phonemeValidation.confidence > 0.4) qualityScores.push(2);
    else qualityScores.push(1);
  }

  // Lip sync quality score
  if (lipSyncValidation) {
    if (lipSyncValidation.accuracy > 0.8) qualityScores.push(4);
    else if (lipSyncValidation.accuracy > 0.6) qualityScores.push(3);
    else if (lipSyncValidation.accuracy > 0.4) qualityScores.push(2);
    else qualityScores.push(1);
  }

  const averageScore = qualityScores.reduce((a, b) => a + b, 0) / qualityScores.length;

  if (averageScore >= 3.5) return 'excellent';
  if (averageScore >= 2.5) return 'good';
  if (averageScore >= 1.5) return 'fair';
  return 'poor';
};

// ===== VALIDATE PHONEME SYNC =====
const validatePhonemeSync = async (audioPath, phonemeAlignment, jobId) => {
  console.log(`[${jobId}] Validating phoneme sync...`);

  try {
    if (!phonemeAlignment.phoneme_timings || phonemeAlignment.phoneme_timings.length === 0) {
      return { confidence: 0.1, accuracy: 0.1, method: 'no_phonemes' };
    }

    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const lastTiming = phonemeAlignment.phoneme_timings[phonemeAlignment.phoneme_timings.length - 1];
    const phonemeDuration = lastTiming.end;

    const durationMatch = Math.abs(audioDuration - phonemeDuration) < 0.5;
    const confidence = durationMatch ? 0.8 : 0.4;

    return {
      confidence,
      accuracy: confidence,
      method: 'phoneme_duration_match',
      audioDuration,
      phonemeDuration,
      durationMatch
    };

  } catch (error) {
    console.error(`[${jobId}] Phoneme sync validation failed:`, error.message);
    return { confidence: 0.1, accuracy: 0.1, method: 'error', error: error.message };
  }
};

// ===== VALIDATE AGAINST LIP SYNC POINTS =====
const validateAgainstLipSyncPoints = async (audioPath, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Validating against lip sync points...`);

  try {
    if (!lipSyncReference.sync_points || lipSyncReference.sync_points.length === 0) {
      return { confidence: 0.1, accuracy: 0.1, method: 'no_sync_points' };
    }

    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const videoDuration = lipSyncReference.total_duration;

    const durationMatch = Math.abs(audioDuration - videoDuration) / videoDuration < 0.05; // 5% tolerance
    const confidence = durationMatch ? 0.7 : 0.3;

    return {
      confidence,
      accuracy: confidence,
      method: 'lip_sync_duration_match',
      audioDuration,
      videoDuration,
      durationMatch
    };

  } catch (error) {
    console.error(`[${jobId}] Lip sync point validation failed:`, error.message);
    return { confidence: 0.1, accuracy: 0.1, method: 'error', error: error.message };
  }
};

// ===== CALCULATE LIP SYNC ACCURACY =====
const calculateLipSyncAccuracy = async (audioPath, lipSyncReference, jobId) => {
  console.log(`[${jobId}] Calculating lip sync accuracy...`);

  try {
    const audioDuration = await getUltraPreciseAudioDuration(audioPath);
    const referenceDuration = lipSyncReference.total_duration;

    const durationAccuracy = 1 - Math.abs(audioDuration - referenceDuration) / referenceDuration;
    const syncPointsCount = lipSyncReference.sync_points.length;
    const confidenceLevel = lipSyncReference.confidence_level;

    // Calculate match score based on multiple factors
    let matchScore = durationAccuracy * 0.6; // 60% weight to duration
    matchScore += (syncPointsCount / 20) * 0.2; // 20% weight to sync point density
    matchScore += (confidenceLevel === 'high' ? 0.2 : confidenceLevel === 'medium' ? 0.1 : 0.05); // 20% weight to confidence

    matchScore = Math.min(1.0, Math.max(0.0, matchScore));

    const grade = matchScore > 0.9 ? 'excellent' :
      matchScore > 0.8 ? 'good' :
        matchScore > 0.7 ? 'fair' : 'poor';

    return {
      accuracy: durationAccuracy,
      matchScore: matchScore,
      grade: grade,
      confidence: confidenceLevel === 'high' ? 0.9 : confidenceLevel === 'medium' ? 0.7 : 0.5,
      details: {
        audioDuration,
        referenceDuration,
        syncPointsCount,
        confidenceLevel,
        durationDifference: Math.abs(audioDuration - referenceDuration)
      }
    };

  } catch (error) {
    console.error(`[${jobId}] Lip sync accuracy calculation failed:`, error.message);

    return {
      accuracy: 0.1,
      matchScore: 0.1,
      grade: 'poor',
      confidence: 0.1,
      error: error.message
    };
  }
};

// ===== CLEANUP ADVANCED TEMPORARY FILES =====
const cleanupAdvancedTemporaryFiles = async (tempFiles, originalFile, jobId) => {
  console.log(`[${jobId}] Performing advanced cleanup of temporary files...`);

  let cleanedFiles = 0;
  let cleanupErrors = 0;

  for (const tempFile of tempFiles) {
    if (tempFile !== originalFile && fs.existsSync(tempFile)) {
      try {
        const fileStats = fs.statSync(tempFile);
        fs.unlinkSync(tempFile);
        cleanedFiles++;
        console.log(`[${jobId}] Cleaned: ${path.basename(tempFile)} (${Math.round(fileStats.size / 1024)}KB)`);
      } catch (cleanupError) {
        cleanupErrors++;
        console.warn(`[${jobId}] Failed to cleanup ${path.basename(tempFile)}:`, cleanupError.message);
      }
    }
  }

  console.log(`[${jobId}] Advanced cleanup completed: ${cleanedFiles} files removed, ${cleanupErrors} errors`);

  // Optional: Cleanup empty directories
  const tempDirs = [
    './uploads/temp_audio',
    './uploads/sync',
    './uploads/neural_align'
  ];

  for (const tempDir of tempDirs) {
    try {
      if (fs.existsSync(tempDir)) {
        const files = fs.readdirSync(tempDir);
        if (files.length === 0) {
          fs.rmdirSync(tempDir);
          console.log(`[${jobId}] Removed empty directory: ${tempDir}`);
        }
      }
    } catch (dirCleanupError) {
      console.warn(`[${jobId}] Failed to cleanup directory ${tempDir}:`, dirCleanupError.message);
    }
  }
};

// ===== LEGACY FUNCTIONS FOR COMPATIBILITY =====

export const discoverJobFiles = discoverJobFilesAdvanced;

export const validateAudioVideoDurations = async (videoPath, audioPath, jobId) => {
  const frameLevelValidation = await performFrameLevelDurationValidation(videoPath, audioPath, null, null, jobId);

  return {
    videoDuration: frameLevelValidation.videoDuration,
    audioDuration: frameLevelValidation.audioDuration,
    durationDifference: frameLevelValidation.durationDifference,
    durationsMatch: frameLevelValidation.syncQuality !== 'poor',
    tolerance: 1.5,
    severity: frameLevelValidation.syncQuality === 'poor' ? 'critical' :
      frameLevelValidation.syncQuality === 'fair' ? 'warning' : 'acceptable'
  };
};

export const correctAudioDurationMismatch = async (audioPath, videoPath, durationValidation, jobId) => {
  console.log(`[${jobId}] Using enhanced real-time sync adjustment for duration correction...`);

  const frameLevelValidation = {
    videoDuration: durationValidation.videoDuration,
    audioDuration: durationValidation.audioDuration,
    durationDifference: durationValidation.durationDifference,
    frameAccuracy: durationValidation.durationDifference / (1 / 30), // Assume 30fps
    frameDuration: 1 / 30,
    fps: 30,
    syncQuality: durationValidation.severity === 'critical' ? 'poor' :
      durationValidation.severity === 'warning' ? 'fair' : 'good',
    requiresAdjustment: !durationValidation.durationsMatch,
    adjustmentStrategy: 'fine_tuning'
  };

  return await performRealTimeSyncAdjustment(audioPath, videoPath, frameLevelValidation, null, null, jobId);
};

export const getMediaDuration = getUltraPreciseVideoDuration;

export const assembleVideoWithAudioOnly = async (jobId) => {
  console.log(`[${jobId}] Using enhanced assembly for audio-only processing...`);
  return await assembleVideoWithCaptions(jobId, null, null);
};

// ===== CONTINUATION OF videoService.js =====

export const getVideoInfo = async (videoPath, jobId) => {
  try {
    const metadata = await getUltraPreciseVideoMetadata(videoPath);
    const audioMetadata = await getUltraPreciseAudioMetadata(videoPath).catch(() => ({ channels: 0, codec: 'none' }));

    return {
      duration: metadata.duration,
      size: fs.statSync(videoPath).size,
      bitrate: metadata.bitrate,
      fps: metadata.fps,
      resolution: `${metadata.width}x${metadata.height}`,
      videoCodec: metadata.codec,
      audioChannels: audioMetadata.channels,
      audioCodec: audioMetadata.codec,
      frameCount: metadata.frameCount,
      format: path.extname(videoPath).toLowerCase(),
      hasVideo: metadata.width > 0 && metadata.height > 0,
      hasAudio: audioMetadata.channels > 0,
      aspectRatio: metadata.width / metadata.height,
      isPortrait: metadata.height > metadata.width,
      quality: metadata.width >= 1920 ? 'HD' : metadata.width >= 1280 ? 'HD Ready' : 'SD',
      info: {
        created: fs.statSync(videoPath).birthtime,
        modified: fs.statSync(videoPath).mtime,
        sizeFormatted: formatFileSize(fs.statSync(videoPath).size),
        durationFormatted: formatDuration(metadata.duration)
      }
    };

  } catch (error) {
    console.error(`[${jobId}] Video info extraction failed:`, error.message);

    // Return minimal info with file stats only
    const stats = fs.existsSync(videoPath) ? fs.statSync(videoPath) : null;
    return {
      duration: 0,
      size: stats ? stats.size : 0,
      bitrate: 0,
      fps: 0,
      resolution: '0x0',
      videoCodec: 'unknown',
      audioChannels: 0,
      audioCodec: 'unknown',
      frameCount: 0,
      format: path.extname(videoPath).toLowerCase(),
      hasVideo: false,
      hasAudio: false,
      aspectRatio: 0,
      isPortrait: false,
      quality: 'unknown',
      error: error.message,
      info: stats ? {
        created: stats.birthtime,
        modified: stats.mtime,
        sizeFormatted: formatFileSize(stats.size),
        durationFormatted: '0:00'
      } : null
    };
  }
};

// ===== UTILITY FUNCTIONS =====

// Format file size in human readable format
const formatFileSize = (bytes) => {
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
  if (bytes === 0) return '0 Bytes';

  const i = Math.floor(Math.log(bytes) / Math.log(1024));
  return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
};

// Format duration in MM:SS or HH:MM:SS format
const formatDuration = (seconds) => {
  if (isNaN(seconds) || seconds <= 0) return '0:00';

  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);

  if (hours > 0) {
    return `${hours}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  } else {
    return `${minutes}:${secs.toString().padStart(2, '0')}`;
  }
};

// ===== ENHANCED SUBTITLE PROCESSING =====

export const generateSubtitles = async (translation, jobId, targetLanguage, outputFormat = 'vtt') => {
  try {
    console.log(`[${jobId}] Generating subtitles in ${outputFormat.toUpperCase()} format for ${targetLanguage}...`);

    if (!translation || !translation.segments || translation.segments.length === 0) {
      throw new Error('No translation segments available for subtitle generation');
    }

    const outputDir = './uploads/captions';
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    const baseFileName = `${jobId}_captions`;
    const vttPath = path.join(outputDir, `${baseFileName}.vtt`);
    const srtPath = path.join(outputDir, `${baseFileName}.srt`);

    const segments = translation.segments;

    // ===== GENERATE WEBVTT FORMAT =====
    let vttContent = 'WEBVTT\n\n';

    segments.forEach((segment, index) => {
      if (!segment.text || segment.text.trim().length === 0) return;

      const start = formatTimestampVTT(segment.start || (index * 2.5));
      const end = formatTimestampVTT(segment.end || ((index + 1) * 2.5));

      vttContent += `${index + 1}\n`;
      vttContent += `${start} --> ${end}\n`;
      vttContent += `${segment.text.trim()}\n\n`;
    });

    fs.writeFileSync(vttPath, vttContent, 'utf8');

    // ===== GENERATE SRT FORMAT =====
    let srtContent = '';

    segments.forEach((segment, index) => {
      if (!segment.text || segment.text.trim().length === 0) return;

      const start = formatTimestampSRT(segment.start || (index * 2.5));
      const end = formatTimestampSRT(segment.end || ((index + 1) * 2.5));

      srtContent += `${index + 1}\n`;
      srtContent += `${start} --> ${end}\n`;
      srtContent += `${segment.text.trim()}\n\n`;
    });

    fs.writeFileSync(srtPath, srtContent, 'utf8');

    console.log(`[${jobId}] ‚úÖ Subtitles generated successfully:`);
    console.log(`[${jobId}]   WebVTT: ${vttPath} (${fs.statSync(vttPath).size} bytes)`);
    console.log(`[${jobId}]   SRT: ${srtPath} (${fs.statSync(srtPath).size} bytes)`);
    console.log(`[${jobId}]   Segments: ${segments.length}`);
    console.log(`[${jobId}]   Language: ${targetLanguage}`);

    return {
      vttPath,
      srtPath,
      segmentCount: segments.length,
      language: targetLanguage,
      vttSize: fs.statSync(vttPath).size,
      srtSize: fs.statSync(srtPath).size,
      success: true
    };

  } catch (error) {
    console.error(`[${jobId}] Subtitle generation failed:`, error.message);
    throw error;
  }
};

// Format timestamp for WebVTT format (HH:MM:SS.mmm)
const formatTimestampVTT = (seconds) => {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const milliseconds = Math.floor((seconds % 1) * 1000);

  return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${milliseconds.toString().padStart(3, '0')}`;
};

// Format timestamp for SRT format (HH:MM:SS,mmm)
const formatTimestampSRT = (seconds) => {
  const timestamp = formatTimestampVTT(seconds);
  return timestamp.replace('.', ','); // SRT uses comma instead of dot
};

// ===== ADVANCED VIDEO PROCESSING FUNCTIONS =====

export const extractVideoThumbnails = async (videoPath, jobId, count = 5) => {
  console.log(`[${jobId}] Extracting ${count} thumbnails from video...`);

  try {
    const outputDir = `./uploads/thumbnails/${jobId}`;
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    const videoMetadata = await getUltraPreciseVideoMetadata(videoPath);
    const duration = videoMetadata.duration;
    const interval = duration / (count + 1); // Evenly spaced thumbnails

    const thumbnailPaths = [];
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');

    for (let i = 1; i <= count; i++) {
      const timestamp = i * interval;
      const outputPath = path.join(outputDir, `thumbnail_${i}.jpg`);
      const outputPathFixed = path.resolve(outputPath).replace(/\\/g, '/');

      const command = `ffmpeg -i "${videoPathFixed}" -ss ${timestamp.toFixed(2)} -vframes 1 -vf "scale=320:180" -y "${outputPathFixed}"`;

      try {
        await execAsync(command);

        if (fs.existsSync(outputPath)) {
          thumbnailPaths.push({
            path: outputPath,
            timestamp: timestamp,
            index: i,
            size: fs.statSync(outputPath).size
          });
        }
      } catch (thumbError) {
        console.warn(`[${jobId}] Failed to generate thumbnail ${i}:`, thumbError.message);
      }
    }

    console.log(`[${jobId}] ‚úÖ Generated ${thumbnailPaths.length}/${count} thumbnails`);

    return {
      thumbnails: thumbnailPaths,
      totalGenerated: thumbnailPaths.length,
      totalRequested: count,
      outputDirectory: outputDir,
      videoDuration: duration
    };

  } catch (error) {
    console.error(`[${jobId}] Thumbnail extraction failed:`, error.message);
    throw error;
  }
};

export const analyzeVideoQuality = async (videoPath, jobId) => {
  console.log(`[${jobId}] Analyzing video quality metrics...`);

  try {
    const metadata = await getUltraPreciseVideoMetadata(videoPath);
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');

    // Extract quality metrics using ffprobe
    const qualityCommand = `ffprobe -v quiet -select_streams v:0 -show_entries frame=pkt_pts_time,pict_type -of csv=p=0 "${videoPathFixed}" | head -100`;

    let frameAnalysis = { iFrames: 0, pFrames: 0, bFrames: 0, totalFrames: 0 };

    try {
      const { stdout } = await execAsync(qualityCommand);
      const frames = stdout.trim().split('\n').filter(line => line.trim());

      frames.forEach(frame => {
        const [timestamp, type] = frame.split(',');
        frameAnalysis.totalFrames++;

        if (type === 'I') frameAnalysis.iFrames++;
        else if (type === 'P') frameAnalysis.pFrames++;
        else if (type === 'B') frameAnalysis.bFrames++;
      });
    } catch (frameError) {
      console.warn(`[${jobId}] Frame analysis failed:`, frameError.message);
    }

    // Calculate quality scores
    const resolutionScore = calculateResolutionScore(metadata.width, metadata.height);
    const bitrateScore = calculateBitrateScore(metadata.bitrate, metadata.width, metadata.height);
    const frameRateScore = calculateFrameRateScore(metadata.fps);

    const overallScore = (resolutionScore + bitrateScore + frameRateScore) / 3;

    const qualityGrade = overallScore >= 8 ? 'Excellent' :
      overallScore >= 6 ? 'Good' :
        overallScore >= 4 ? 'Fair' : 'Poor';

    const analysis = {
      resolution: {
        width: metadata.width,
        height: metadata.height,
        pixels: metadata.width * metadata.height,
        quality: getResolutionQuality(metadata.width, metadata.height),
        score: resolutionScore
      },
      bitrate: {
        value: metadata.bitrate,
        formatted: formatBitrate(metadata.bitrate),
        score: bitrateScore,
        adequacy: getBitrateAdequacy(metadata.bitrate, metadata.width, metadata.height)
      },
      frameRate: {
        fps: metadata.fps,
        score: frameRateScore,
        category: getFrameRateCategory(metadata.fps)
      },
      frames: frameAnalysis,
      overall: {
        score: overallScore,
        grade: qualityGrade,
        recommendations: generateQualityRecommendations(metadata, overallScore)
      },
      technical: {
        codec: metadata.codec,
        duration: metadata.duration,
        frameCount: metadata.frameCount,
        aspectRatio: (metadata.width / metadata.height).toFixed(2),
        isHDR: false, // Would require more advanced analysis
        colorSpace: 'unknown' // Would require more advanced analysis
      }
    };

    console.log(`[${jobId}] ‚úÖ Video quality analysis completed:`);
    console.log(`[${jobId}]   Overall grade: ${qualityGrade} (${overallScore.toFixed(1)}/10)`);
    console.log(`[${jobId}]   Resolution: ${metadata.width}x${metadata.height} (${analysis.resolution.quality})`);
    console.log(`[${jobId}]   Bitrate: ${analysis.bitrate.formatted} (${analysis.bitrate.adequacy})`);
    console.log(`[${jobId}]   Frame rate: ${metadata.fps}fps (${analysis.frameRate.category})`);

    return analysis;

  } catch (error) {
    console.error(`[${jobId}] Video quality analysis failed:`, error.message);
    throw error;
  }
};

// ===== QUALITY CALCULATION HELPER FUNCTIONS =====

const calculateResolutionScore = (width, height) => {
  const pixels = width * height;

  if (pixels >= 8294400) return 10; // 4K+ (3840x2160)
  if (pixels >= 2073600) return 9;  // 1440p (2560x1440)
  if (pixels >= 2073600) return 8;  // 1080p (1920x1080)
  if (pixels >= 921600) return 6;   // 720p (1280x720)
  if (pixels >= 409920) return 4;   // 480p (854x480)
  if (pixels >= 230400) return 3;   // 360p (640x360)
  return 2; // Below 360p
};

const calculateBitrateScore = (bitrate, width, height) => {
  if (!bitrate) return 5; // Unknown bitrate

  const pixels = width * height;
  const bitsPerPixel = bitrate / pixels;

  // Optimal bits per pixel for different resolutions
  let optimalBPP = 0.1; // Default

  if (pixels >= 8294400) optimalBPP = 0.05; // 4K
  else if (pixels >= 2073600) optimalBPP = 0.07; // 1440p
  else if (pixels >= 2073600) optimalBPP = 0.1; // 1080p
  else if (pixels >= 921600) optimalBPP = 0.15; // 720p
  else optimalBPP = 0.2; // Lower resolutions

  const ratio = bitsPerPixel / optimalBPP;

  if (ratio >= 1.5) return 10; // High bitrate
  if (ratio >= 1.0) return 8;  // Good bitrate
  if (ratio >= 0.7) return 6;  // Adequate bitrate
  if (ratio >= 0.5) return 4;  // Low bitrate
  return 2; // Very low bitrate
};

const calculateFrameRateScore = (fps) => {
  if (fps >= 60) return 10; // High frame rate
  if (fps >= 30) return 8;  // Standard frame rate
  if (fps >= 24) return 6;  // Cinematic frame rate
  if (fps >= 15) return 4;  // Low frame rate
  return 2; // Very low frame rate
};

const getResolutionQuality = (width, height) => {
  const pixels = width * height;

  if (pixels >= 8294400) return '4K Ultra HD';
  if (pixels >= 2073600) return 'Quad HD (1440p)';
  if (pixels >= 2073600) return 'Full HD (1080p)';
  if (pixels >= 921600) return 'HD (720p)';
  if (pixels >= 409920) return 'SD (480p)';
  if (pixels >= 230400) return 'Low (360p)';
  return 'Very Low';
};

const getBitrateAdequacy = (bitrate, width, height) => {
  if (!bitrate) return 'Unknown';

  const mbps = bitrate / 1000000;
  const pixels = width * height;

  let recommended = 5; // Default 5 Mbps for HD

  if (pixels >= 8294400) recommended = 25; // 4K
  else if (pixels >= 2073600) recommended = 15; // 1440p
  else if (pixels >= 2073600) recommended = 8; // 1080p
  else if (pixels >= 921600) recommended = 5; // 720p
  else recommended = 2; // SD

  const ratio = mbps / recommended;

  if (ratio >= 1.5) return 'Excellent';
  if (ratio >= 1.0) return 'Good';
  if (ratio >= 0.7) return 'Adequate';
  if (ratio >= 0.5) return 'Low';
  return 'Very Low';
};

const getFrameRateCategory = (fps) => {
  if (fps >= 60) return 'High Frame Rate';
  if (fps >= 30) return 'Standard';
  if (fps >= 24) return 'Cinematic';
  if (fps >= 15) return 'Low';
  return 'Very Low';
};

const formatBitrate = (bitrate) => {
  if (!bitrate) return 'Unknown';

  const mbps = bitrate / 1000000;

  if (mbps >= 1) {
    return `${mbps.toFixed(1)} Mbps`;
  } else {
    const kbps = bitrate / 1000;
    return `${kbps.toFixed(0)} kbps`;
  }
};

const generateQualityRecommendations = (metadata, overallScore) => {
  const recommendations = [];

  if (metadata.width < 1280) {
    recommendations.push('Consider using higher resolution source material (720p minimum recommended)');
  }

  if (metadata.fps < 24) {
    recommendations.push('Frame rate appears low - consider 24fps minimum for smooth playback');
  }

  if (metadata.bitrate && metadata.bitrate < 2000000) {
    recommendations.push('Bitrate may be too low for optimal quality - consider increasing encoding bitrate');
  }

  if (overallScore < 6) {
    recommendations.push('Overall video quality could be improved - consider re-encoding with higher quality settings');
  }

  if (recommendations.length === 0) {
    recommendations.push('Video quality appears to be good - no immediate improvements needed');
  }

  return recommendations;
};

// ===== BATCH PROCESSING FUNCTIONS =====

export const batchProcessVideos = async (jobIds, processingOptions = {}) => {
  console.log(`Starting batch processing for ${jobIds.length} videos...`);

  const results = {
    total: jobIds.length,
    successful: 0,
    failed: 0,
    details: [],
    startTime: Date.now(),
    endTime: null,
    processingTime: 0
  };

  for (let i = 0; i < jobIds.length; i++) {
    const jobId = jobIds[i];
    const progress = `${i + 1}/${jobIds.length}`;

    console.log(`[BATCH] Processing ${progress}: ${jobId}`);

    try {
      const jobResult = await assembleVideoWithCaptions(jobId, null, null);

      results.successful++;
      results.details.push({
        jobId,
        status: 'success',
        outputPath: jobResult.outputPath,
        processingTime: jobResult.processingStats?.totalProcessingTime || 0,
        quality: jobResult.validation?.overallQuality || 'unknown'
      });

      console.log(`[BATCH] ‚úÖ ${progress} completed: ${jobId}`);

    } catch (error) {
      results.failed++;
      results.details.push({
        jobId,
        status: 'failed',
        error: error.message,
        timestamp: new Date().toISOString()
      });

      console.error(`[BATCH] ‚ùå ${progress} failed: ${jobId} - ${error.message}`);
    }

    // Small delay between jobs to prevent overwhelming the system
    if (i < jobIds.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }

  results.endTime = Date.now();
  results.processingTime = results.endTime - results.startTime;

  console.log(`[BATCH] ‚úÖ Batch processing completed:`);
  console.log(`[BATCH]   Total: ${results.total}`);
  console.log(`[BATCH]   Successful: ${results.successful}`);
  console.log(`[BATCH]   Failed: ${results.failed}`);
  console.log(`[BATCH]   Processing time: ${formatDuration(results.processingTime / 1000)}`);

  return results;
};

// ===== ERROR RECOVERY FUNCTIONS =====

export const recoverFromProcessingError = async (jobId, lastKnownState = null) => {
  console.log(`[${jobId}] Attempting error recovery...`);

  try {
    // Discover what files we have available
    const filePaths = await discoverJobFilesAdvanced(jobId);

    const recovery = {
      jobId,
      recoveryAttempted: true,
      availableFiles: {
        originalVideo: !!filePaths.originalVideo,
        translatedAudio: !!filePaths.translatedAudio,
        captions: !!filePaths.captions,
        transcript: !!filePaths.transcript
      },
      recoveryStrategy: null,
      recoveryResult: null
    };

    // Determine recovery strategy
    if (filePaths.originalVideo && filePaths.translatedAudio) {
      recovery.recoveryStrategy = 'full_assembly_retry';
      console.log(`[${jobId}] Recovery strategy: Full assembly retry`);

      try {
        recovery.recoveryResult = await assembleVideoWithCaptions(jobId, null, null);
        recovery.recoverySuccessful = true;

        console.log(`[${jobId}] ‚úÖ Full recovery successful`);

      } catch (assemblyError) {
        recovery.recoverySuccessful = false;
        recovery.recoveryError = assemblyError.message;

        // Try simpler assembly without advanced features
        console.log(`[${jobId}] Trying simplified assembly...`);

        try {
          recovery.recoveryResult = await performSimplifiedAssembly(
            filePaths.originalVideo,
            filePaths.translatedAudio,
            filePaths.captions,
            jobId
          );
          recovery.recoverySuccessful = true;
          recovery.recoveryStrategy = 'simplified_assembly';

          console.log(`[${jobId}] ‚úÖ Simplified recovery successful`);

        } catch (simplifiedError) {
          recovery.recoverySuccessful = false;
          recovery.recoveryError = simplifiedError.message;
          console.error(`[${jobId}] ‚ùå Both recovery methods failed`);
        }
      }

    } else {
      recovery.recoveryStrategy = 'insufficient_files';
      recovery.recoverySuccessful = false;
      recovery.recoveryError = 'Required files not available for recovery';

      console.error(`[${jobId}] ‚ùå Recovery impossible - missing required files`);
    }

    return recovery;

  } catch (error) {
    console.error(`[${jobId}] Recovery attempt failed:`, error.message);

    return {
      jobId,
      recoveryAttempted: true,
      recoverySuccessful: false,
      recoveryError: error.message,
      availableFiles: {},
      recoveryStrategy: 'error'
    };
  }
};

// ===== SIMPLIFIED ASSEMBLY FOR ERROR RECOVERY =====
const performSimplifiedAssembly = async (videoPath, audioPath, captionPath, jobId) => {
  console.log(`[${jobId}] Performing simplified assembly for error recovery...`);

  const outputPath = `./uploads/processed/${jobId}_final_recovered.mp4`;

  // Ensure output directory exists
  const outputDir = path.dirname(outputPath);
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  return new Promise((resolve, reject) => {
    // ‚úÖ FIXED: Simple assembly with proper path handling and subtitle embedding
    const videoPathFixed = path.resolve(videoPath).replace(/\\/g, '/');
    const audioPathFixed = path.resolve(audioPath).replace(/\\/g, '/');
    const outputPathFixed = path.resolve(outputPath).replace(/\\/g, '/');

    let command = [
      'ffmpeg',
      '-i', `"${videoPathFixed}"`,
      '-i', `"${audioPathFixed}"`
    ];

    // Add subtitle filter if captions exist (FIXED for Windows)
    if (captionPath && fs.existsSync(captionPath)) {
      const captionPathForFFmpeg = path.resolve(captionPath).replace(/\\/g, '/');
      // Use hex format without ampersands
      command.push('-vf', `"scale=-2:720,fps=50,subtitles='${captionPathForFFmpeg}':force_style='FontSize=16,PrimaryColour=0xFFFFFF,OutlineColour=0x000000,Outline=2'"`);
    }


    // Simple encoding options
    command = command.concat([
      '-c:v', 'libx264',
      '-c:a', 'aac',
      '-preset', 'fast',
      '-crf', '25',
      '-y', `"${outputPathFixed}"`
    ]);

    const ffmpegCommand = command.join(' ');

    console.log(`[${jobId}] Simplified assembly command: ${ffmpegCommand.substring(0, 150)}...`);

    exec(ffmpegCommand, {
      maxBuffer: 1024 * 1024 * 100, // 100MB buffer
      timeout: 300000 // 5 minutes
    }, (error, stdout, stderr) => {
      if (error) {
        console.error(`[${jobId}] Simplified assembly failed:`, error.message);
        reject(error);
        return;
      }

      if (!fs.existsSync(outputPath)) {
        reject(new Error('Simplified assembly completed but output file not found'));
        return;
      }

      const outputStats = fs.statSync(outputPath);

      if (outputStats.size < 50000) {
        reject(new Error(`Simplified assembly output too small: ${outputStats.size} bytes`));
        return;
      }

      console.log(`[${jobId}] ‚úÖ Simplified assembly completed: ${Math.round(outputStats.size / 1024 / 1024)}MB`);

      resolve({
        outputPath,
        fileSize: outputStats.size,
        method: 'simplified_recovery',
        timestamp: new Date().toISOString()
      });
    });
  });
};

// ===== SYSTEM HEALTH AND MONITORING =====

export const getProcessingSystemHealth = async () => {
  console.log('Checking video processing system health...');

  const health = {
    timestamp: new Date().toISOString(),
    ffmpeg: { available: false, version: null },
    diskSpace: { available: 0, total: 0, percentUsed: 0 },
    directories: {},
    processing: {
      activeJobs: 0,
      queuedJobs: 0,
      failedJobs: 0
    },
    recommendations: []
  };

  try {
    // Check FFmpeg availability
    try {
      const { stdout } = await execAsync('ffmpeg -version');
      health.ffmpeg.available = true;
      health.ffmpeg.version = stdout.split('\n')[0].match(/ffmpeg version ([^\s]+)/)?.[1] || 'unknown';
    } catch (ffmpegError) {
      health.ffmpeg.available = false;
      health.recommendations.push('FFmpeg not found - install FFmpeg for video processing');
    }

    // Check critical directories
    const criticalDirs = [
      './uploads',
      './uploads/originals',
      './uploads/processed',
      './uploads/translated_audio',
      './uploads/captions',
      './uploads/transcripts'
    ];

    for (const dir of criticalDirs) {
      health.directories[dir] = {
        exists: fs.existsSync(dir),
        writable: false,
        fileCount: 0
      };

      if (health.directories[dir].exists) {
        try {
          // Test write access
          const testFile = path.join(dir, '.health_test');
          fs.writeFileSync(testFile, 'test');
          fs.unlinkSync(testFile);
          health.directories[dir].writable = true;

          // Count files
          const files = fs.readdirSync(dir);
          health.directories[dir].fileCount = files.length;

        } catch (accessError) {
          health.directories[dir].writable = false;
          health.recommendations.push(`Directory ${dir} is not writable`);
        }
      } else {
        health.recommendations.push(`Critical directory missing: ${dir}`);
      }
    }

    // Check disk space (simplified - would need platform-specific implementation for accuracy)
    try {
      const uploadsDir = './uploads';
      if (fs.existsSync(uploadsDir)) {
        const stats = fs.statSync(uploadsDir);
        // This is a simplified approach - real disk space checking would need platform-specific code
        health.diskSpace.available = 1000000000; // Placeholder: 1GB
        health.diskSpace.total = 10000000000; // Placeholder: 10GB
        health.diskSpace.percentUsed = 10; // Placeholder: 10%
      }
    } catch (diskError) {
      health.recommendations.push('Unable to check disk space');
    }

    // Add general recommendations based on health
    if (!health.ffmpeg.available) {
      health.recommendations.push('Install FFmpeg: https://ffmpeg.org/download.html');
    }

    if (health.diskSpace.percentUsed > 90) {
      health.recommendations.push('Disk space is running low - consider cleanup');
    }

    const missingDirs = Object.entries(health.directories).filter(([dir, info]) => !info.exists);
    if (missingDirs.length > 0) {
      health.recommendations.push('Create missing directories or run system initialization');
    }

    if (health.recommendations.length === 0) {
      health.recommendations.push('System appears healthy - no issues detected');
    }

    console.log('‚úÖ System health check completed');
    console.log(`   FFmpeg: ${health.ffmpeg.available ? '‚úÖ Available' : '‚ùå Missing'}`);
    console.log(`   Directories: ${Object.values(health.directories).filter(d => d.exists).length}/${Object.keys(health.directories).length} OK`);
    console.log(`   Recommendations: ${health.recommendations.length}`);

    return health;

  } catch (error) {
    console.error('System health check failed:', error.message);

    health.error = error.message;
    health.recommendations.push('System health check encountered errors - manual inspection recommended');

    return health;
  }
};


export const resumeProcessing = async (jobId, fromStep = 1) => {
  console.log(`[${jobId}] Resuming processing from step ${fromStep}...`);
  return await assembleVideoWithCaptions(jobId, null, null);
};



// ===== EXPORT ALL FUNCTIONS =====
export default {
  // Main processing functions
  assembleVideoWithCaptions,
  assembleVideoWithAudioOnly,

  // File discovery and validation
  discoverJobFiles: discoverJobFilesAdvanced,
  validateAudioVideoDurations,
  correctAudioDurationMismatch,

  // Media information and analysis
  getVideoInfo,
  getMediaDuration,
  analyzeVideoQuality,
  extractVideoThumbnails,

  // Subtitle and caption functions
  generateSubtitles,

  // Batch processing and error recovery
  batchProcessVideos,
  recoverFromProcessingError,

  // System health and monitoring
  getProcessingSystemHealth,

  // Utility functions
  formatFileSize,
  formatDuration,
  formatTimestampVTT,
  formatTimestampSRT,
  resumeProcessing,           // Add this
  escapeSubtitlePath
};
